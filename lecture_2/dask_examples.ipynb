{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line\n",
    "\n",
    "\n",
    "This is the most fundamental way to deploy Dask on multiple machines. In production environments, this process is often automated by some other resource manager. Hence, it is rare that people need to follow these instructions explicitly. But since we want learn how to \"build\" a cluster we want study how to start it from the command line.\n",
    "\n",
    "A ```dask.distributed``` network consists of one ```dask-scheduler``` process and several ```dask-worker``` processes that connect to that scheduler. These are normal Python processes that can be executed from the command line. We launch the dask-scheduler executable in one process and the dask-worker executable in several processes, possibly on different machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, respect to the revious lectures, today we want to create a cluster \"from scratch\" using IP addresses and real workers and not the automatic \"local cluster\" created by dask.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first let's see how works the ```dask-scheduler``` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: dask-scheduler [OPTIONS] [PRELOAD_ARGV]...\n",
      "\n",
      "Options:\n",
      "  --host TEXT                   URI, IP or hostname of this server\n",
      "  --port INTEGER                Serving port\n",
      "  --interface TEXT              Preferred network interface like 'eth0' or\n",
      "                                'ib0'\n",
      "\n",
      "  --protocol TEXT               Protocol like tcp, tls, or ucx\n",
      "  --tls-ca-file PATH            CA cert(s) file for TLS (in PEM format)\n",
      "  --tls-cert PATH               certificate file for TLS (in PEM format)\n",
      "  --tls-key PATH                private key file for TLS (in PEM format)\n",
      "  --bokeh-port INTEGER          Deprecated.  See --dashboard-address\n",
      "  --dashboard-address TEXT      Address on which to listen for diagnostics\n",
      "                                dashboard  [default: :8787]\n",
      "\n",
      "  --dashboard / --no-dashboard  Launch the Dashboard [default: --dashboard]\n",
      "  --bokeh / --no-bokeh          Deprecated.  See --dashboard/--no-dashboard.\n",
      "  --show / --no-show            Show web UI [default: --show]\n",
      "  --dashboard-prefix TEXT       Prefix for the dashboard app\n",
      "  --use-xheaders BOOLEAN        User xheaders in dashboard app for ssl\n",
      "                                termination in header  [default: False]\n",
      "\n",
      "  --pid-file TEXT               File to write the process PID\n",
      "  --scheduler-file TEXT         File to write connection information. This may\n",
      "                                be a good way to share connection information\n",
      "                                if your cluster is on a shared network file\n",
      "                                system.\n",
      "\n",
      "  --preload TEXT                Module that should be loaded by the scheduler\n",
      "                                process  like \"foo.bar\" or \"/path/to/foo.py\".\n",
      "\n",
      "  --idle-timeout TEXT           Time of inactivity after which to kill the\n",
      "                                scheduler\n",
      "\n",
      "  --version                     Show the version and exit.\n",
      "  --help                        Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "dask-scheduler --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "#dask-scheduler run it inside a real bash terminal not from jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command ```dask-worker``` on the rest of the nodes. Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: dask-worker [OPTIONS] [SCHEDULER] [PRELOAD_ARGV]...\n",
      "\n",
      "Options:\n",
      "  --tls-ca-file PATH              CA cert(s) file for TLS (in PEM format)\n",
      "  --tls-cert PATH                 certificate file for TLS (in PEM format)\n",
      "  --tls-key PATH                  private key file for TLS (in PEM format)\n",
      "  --worker-port TEXT              Serving computation port, defaults to\n",
      "                                  random. When creating multiple workers with\n",
      "                                  --nprocs, a sequential range of worker ports\n",
      "                                  may be used by specifying the first and last\n",
      "                                  available ports like <first-port>:<last-\n",
      "                                  port>. For example, --worker-port=3000:3026\n",
      "                                  will use ports 3000, 3001, ..., 3025, 3026.\n",
      "\n",
      "  --nanny-port TEXT               Serving nanny port, defaults to random. When\n",
      "                                  creating multiple nannies with --nprocs, a\n",
      "                                  sequential range of nanny ports may be used\n",
      "                                  by specifying the first and last available\n",
      "                                  ports like <first-port>:<last-port>. For\n",
      "                                  example, --nanny-port=3000:3026 will use\n",
      "                                  ports 3000, 3001, ..., 3025, 3026.\n",
      "\n",
      "  --bokeh-port INTEGER            Deprecated.  See --dashboard-address\n",
      "  --dashboard-address TEXT        Address on which to listen for diagnostics\n",
      "                                  dashboard\n",
      "\n",
      "  --dashboard / --no-dashboard    Launch the Dashboard [default: --dashboard]\n",
      "  --bokeh / --no-bokeh            Deprecated.  See --dashboard/--no-dashboard.\n",
      "  --listen-address TEXT           The address to which the worker binds.\n",
      "                                  Example: tcp://0.0.0.0:9000\n",
      "\n",
      "  --contact-address TEXT          The address the worker advertises to the\n",
      "                                  scheduler for communication with it and\n",
      "                                  other workers. Example: tcp://127.0.0.1:9000\n",
      "\n",
      "  --host TEXT                     Serving host. Should be an ip address that\n",
      "                                  is visible to the scheduler and other\n",
      "                                  workers. See --listen-address and --contact-\n",
      "                                  address if you need different listen and\n",
      "                                  contact addresses. See --interface.\n",
      "\n",
      "  --interface TEXT                Network interface like 'eth0' or 'ib0'\n",
      "  --protocol TEXT                 Protocol like tcp, tls, or ucx\n",
      "  --nthreads INTEGER              Number of threads per process.\n",
      "  --nprocs TEXT                   Number of worker processes to launch. If\n",
      "                                  negative, then (CPU_COUNT + 1 + nprocs) is\n",
      "                                  used. Set to 'auto' to set nprocs and\n",
      "                                  nthreads dynamically based on CPU_COUNT\n",
      "                                  [default: 1]\n",
      "\n",
      "  --name TEXT                     A unique name for this worker like\n",
      "                                  'worker-1'. If used with --nprocs then the\n",
      "                                  process number will be appended like name-0,\n",
      "                                  name-1, name-2, ...\n",
      "\n",
      "  --memory-limit TEXT             Bytes of memory per process that the worker can use.\n",
      "                                  This can be:\n",
      "                                  - an integer (bytes), note 0 is a special case for no memory management.\n",
      "                                  - a float (fraction of total system memory).\n",
      "                                  - a string (like 5GB or 5000M).\n",
      "                                  - 'auto' for automatically computing the memory limit.  [default: auto]\n",
      "\n",
      "  --reconnect / --no-reconnect    Reconnect to scheduler if disconnected\n",
      "                                  [default: --reconnect]\n",
      "\n",
      "  --nanny / --no-nanny            Start workers in nanny process for\n",
      "                                  management [default: --nanny]\n",
      "\n",
      "  --pid-file TEXT                 File to write the process PID\n",
      "  --local-directory TEXT          Directory to place worker files\n",
      "  --resources TEXT                Resources for task constraints like \"GPU=2\n",
      "                                  MEM=10e9\". Resources are applied separately\n",
      "                                  to each worker process (only relevant when\n",
      "                                  starting multiple worker processes with '--\n",
      "                                  nprocs').\n",
      "\n",
      "  --scheduler-file TEXT           Filename to JSON encoded scheduler\n",
      "                                  information. Use with dask-scheduler\n",
      "                                  --scheduler-file\n",
      "\n",
      "  --death-timeout TEXT            Seconds to wait for a scheduler before\n",
      "                                  closing\n",
      "\n",
      "  --dashboard-prefix TEXT         Prefix for the dashboard\n",
      "  --lifetime TEXT                 If provided, shut down the worker after this\n",
      "                                  duration.\n",
      "\n",
      "  --lifetime-stagger TEXT         Random amount by which to stagger lifetime\n",
      "                                  values  [default: 0 seconds]\n",
      "\n",
      "  --worker-class TEXT             Worker class used to instantiate workers\n",
      "                                  from.  [default: dask.distributed.Worker]\n",
      "\n",
      "  --lifetime-restart / --no-lifetime-restart\n",
      "                                  Whether or not to restart the worker after\n",
      "                                  the lifetime lapses. This assumes that you\n",
      "                                  are using the --lifetime and --nanny\n",
      "                                  keywords  [default: False]\n",
      "\n",
      "  --preload TEXT                  Module that should be loaded by each worker\n",
      "                                  process like \"foo.bar\" or \"/path/to/foo.py\"\n",
      "\n",
      "  --preload-nanny TEXT            Module that should be loaded by each nanny\n",
      "                                  like \"foo.bar\" or \"/path/to/foo.py\"\n",
      "\n",
      "  --version                       Show the version and exit.\n",
      "  --help                          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "dask-worker --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thisn command must be run by providing the address to the node that hosts ```dask-scheduler```:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#dask-worker 192.168.1.12:8687 run int inside the real command line not from jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic concepts\n",
    "The scheduler and workers both need to accept TCP connections on an open port. By default, the scheduler binds to port 8786 and the worker binds to a random open port. If you are behind a firewall then you may have to open particular ports or tell Dask on a different port.\n",
    "\n",
    "Dask workers are run within a *nanny* process that *monitors* the worker process and restarts it if necessary.\n",
    "\n",
    "As we have saw last lecture, Dask schedulers and even workers host interactive diagnostic web servers using the Bokeh server. These are optional, but generally useful to users. The diagnostic server on the scheduler is particularly valuable, and is served on port 8787."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to create a your first cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first run the cell below in order to indentify your network-card and what your IP is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "ifconfig ##only for those of you that does not use the docker cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open you command line and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask-scheduler --host IP --port 8786"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point open another command line and run this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask-worker IP:8786 --nprocs 2 #this command create 2 workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when is all up to date try to connect to the dashboard and take a look to your new cluster!\n",
    "If you have install all the packages in the correct way you should be able to access to the dashboard at: IP:8787"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an old exercise over the new cluster\n",
    "\n",
    "Try to count how many words are present in all the documents over the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts document present on the dataset: 8283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from dask.distributed import Client\n",
    "import time\n",
    "\n",
    "categories = [\n",
    "     'comp.graphics',\n",
    "     'comp.os.ms-windows.misc',\n",
    "     'comp.sys.ibm.pc.hardware',\n",
    "     'comp.sys.mac.hardware',\n",
    "     'comp.windows.x',\n",
    "     'misc.forsale',\n",
    "     'rec.autos',\n",
    "     'rec.motorcycles',\n",
    "     'rec.sport.baseball',\n",
    "     'rec.sport.hockey',\n",
    "     'sci.crypt',\n",
    "     'sci.electronics',\n",
    "     'sci.med',\n",
    "     'sci.space'\n",
    "]\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='train', categories=categories ).data\n",
    "\n",
    "print(\"Texts document present on the dataset: \"+str(len(dataset)))\n",
    "\n",
    "def count_word_in_statement(text):\n",
    "    \"\"\"\n",
    "    This function takes a text as input and return the number of the words that it contains\n",
    "    \"\"\"\n",
    "    #time.sleep(0.1)\n",
    "    splitted_words = text.split()\n",
    "    return len(splitted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word in the dataset: 2038444\n",
      "Computation took 0.24655771255493164s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "total_words_in_all_data = 0\n",
    "for index in range(0, len(dataset)):\n",
    "    total_words_in_all_data = total_words_in_all_data + count_word_in_statement(dataset[index])\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 41957 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = Client() #change your setting 'dask-scheduler:8786'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word in the dataset: 2038444\n",
      "Computation took 19.2792649269104s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "#futures = client.map(count_word_in_statement, dataset)\n",
    "futures = [client.submit(count_word_in_statement, data) for data in dataset]\n",
    "\n",
    "futures = client.submit(sum, futures)\n",
    "total_words_in_all_data = client.gather(futures)\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why in this case sequential code took more than 10 times less than ditributed version?\n",
    "\n",
    "In general when yuo have to deal with a cluster you have to think about the *overhead* You can image the overhead like the the computational time necessary process your data. \n",
    "Typically in a cluster there two kind of overhead:\n",
    "+ scheduler overhead in serializing the objects that must be sent to workers\n",
    "+ connection overhead. The speed of the network connection between the cluster nodes\n",
    "\n",
    "In the first case, the scheduler adds about one millisecond of overhead per task or Future object. Despite this may sound fast or inconsequential, it's quite slow if you run a large number of tasks. Under this perspective, a larger number of the task means a larger amount of time to create the Future objects of the tasks. \n",
    "In the light of above, if your functions run faster than 100ms or so then you might not see any\n",
    "speedup from using distributed computing, but even worse, probably you might see that the performances get worse.\n",
    "\n",
    "In the second case things are different. The connection overhead may depends from several factors including the stability of the network, the type (wired or WiFi or optic fibe), and bandwith of the network.\n",
    "\n",
    "This is what is happening in the previous example.\n",
    "\n",
    "Let's try to introduce a simulation of intesive computation (a sleep of 10ms: 10 times less the the overhead generated by dask-scheduler):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_in_statement(text):\n",
    "    \"\"\"\n",
    "    This function takes a text as input and return the number of the words that it contains\n",
    "    \"\"\"\n",
    "    splitted_words = text.split()\n",
    "    time.sleep(0.01)\n",
    "    return len(splitted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to run and wait the sequantial code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 50.005530834198s of computation time...\n",
      "More than 50.01652646064758s of computation time...\n",
      "More than 50.02690529823303s of computation time...\n",
      "More than 50.0372576713562s of computation time...\n",
      "More than 50.04771280288696s of computation time...\n",
      "More than 50.0580735206604s of computation time...\n",
      "More than 50.06847405433655s of computation time...\n",
      "More than 50.078811168670654s of computation time...\n",
      "More than 50.089168548583984s of computation time...\n",
      "More than 50.09949254989624s of computation time...\n",
      "More than 50.109891176223755s of computation time...\n",
      "More than 50.12024283409119s of computation time...\n",
      "More than 50.13061189651489s of computation time...\n",
      "More than 50.14093589782715s of computation time...\n",
      "More than 50.1513147354126s of computation time...\n",
      "More than 50.161739349365234s of computation time...\n",
      "More than 50.1721408367157s of computation time...\n",
      "More than 50.18246841430664s of computation time...\n",
      "More than 50.1929132938385s of computation time...\n",
      "More than 50.203511238098145s of computation time...\n",
      "More than 50.21387696266174s of computation time...\n",
      "More than 50.2242705821991s of computation time...\n",
      "More than 50.23491454124451s of computation time...\n",
      "More than 50.24535894393921s of computation time...\n",
      "More than 50.25568222999573s of computation time...\n",
      "More than 50.26601719856262s of computation time...\n",
      "More than 50.2764036655426s of computation time...\n",
      "More than 50.286765575408936s of computation time...\n",
      "More than 50.297107219696045s of computation time...\n",
      "More than 50.30745720863342s of computation time...\n",
      "More than 50.317774295806885s of computation time...\n",
      "More than 50.32813906669617s of computation time...\n",
      "More than 50.33850312232971s of computation time...\n",
      "More than 50.34882211685181s of computation time...\n",
      "More than 50.35922932624817s of computation time...\n",
      "More than 50.369733810424805s of computation time...\n",
      "More than 50.380069732666016s of computation time...\n",
      "More than 50.390440225601196s of computation time...\n",
      "More than 50.40083837509155s of computation time...\n",
      "More than 50.411327838897705s of computation time...\n",
      "More than 50.421769857406616s of computation time...\n",
      "More than 50.43274450302124s of computation time...\n",
      "More than 50.44320631027222s of computation time...\n",
      "More than 50.4536828994751s of computation time...\n",
      "More than 50.464102029800415s of computation time...\n",
      "More than 50.47456908226013s of computation time...\n",
      "More than 50.484915256500244s of computation time...\n",
      "More than 50.49532961845398s of computation time...\n",
      "More than 50.505765438079834s of computation time...\n",
      "More than 50.51616024971008s of computation time...\n",
      "More than 50.527036905288696s of computation time...\n",
      "More than 50.53768491744995s of computation time...\n",
      "More than 50.548075914382935s of computation time...\n",
      "More than 50.55858755111694s of computation time...\n",
      "More than 50.56901431083679s of computation time...\n",
      "More than 50.5793662071228s of computation time...\n",
      "More than 50.589733839035034s of computation time...\n",
      "More than 50.60006093978882s of computation time...\n",
      "More than 50.61043930053711s of computation time...\n",
      "More than 50.62073636054993s of computation time...\n",
      "More than 50.63103652000427s of computation time...\n",
      "More than 50.64148569107056s of computation time...\n",
      "More than 50.65194511413574s of computation time...\n",
      "More than 50.662373542785645s of computation time...\n",
      "More than 50.67299294471741s of computation time...\n",
      "More than 50.68337845802307s of computation time...\n",
      "More than 50.69368553161621s of computation time...\n",
      "More than 50.704087257385254s of computation time...\n",
      "More than 50.714439868927s of computation time...\n",
      "More than 50.724958658218384s of computation time...\n",
      "More than 50.735310316085815s of computation time...\n",
      "More than 50.745787620544434s of computation time...\n",
      "More than 50.756147384643555s of computation time...\n",
      "More than 50.766592264175415s of computation time...\n",
      "More than 50.77710747718811s of computation time...\n",
      "More than 50.78752088546753s of computation time...\n",
      "More than 50.79791736602783s of computation time...\n",
      "More than 50.808250427246094s of computation time...\n",
      "More than 50.81879758834839s of computation time...\n",
      "More than 50.82914328575134s of computation time...\n",
      "More than 50.83947157859802s of computation time...\n",
      "More than 50.850385665893555s of computation time...\n",
      "More than 50.86073637008667s of computation time...\n",
      "More than 50.87114596366882s of computation time...\n",
      "More than 50.8816077709198s of computation time...\n",
      "More than 50.89195799827576s of computation time...\n",
      "More than 50.90234112739563s of computation time...\n",
      "More than 50.913212299346924s of computation time...\n",
      "More than 50.9235315322876s of computation time...\n",
      "More than 50.93414855003357s of computation time...\n",
      "More than 50.94498324394226s of computation time...\n",
      "More than 50.95551872253418s of computation time...\n",
      "More than 50.96583819389343s of computation time...\n",
      "More than 50.976227045059204s of computation time...\n",
      "More than 50.98659014701843s of computation time...\n",
      "More than 50.9970121383667s of computation time...\n",
      "More than 51.00755286216736s of computation time...\n",
      "More than 51.01786470413208s of computation time...\n",
      "More than 51.028197288513184s of computation time...\n",
      "More than 51.038535356521606s of computation time...\n",
      "More than 51.04891300201416s of computation time...\n",
      "More than 51.05934524536133s of computation time...\n",
      "More than 51.069740295410156s of computation time...\n",
      "More than 51.08017539978027s of computation time...\n",
      "More than 51.090728998184204s of computation time...\n",
      "More than 51.101208448410034s of computation time...\n",
      "More than 51.11161184310913s of computation time...\n",
      "More than 51.122217655181885s of computation time...\n",
      "More than 51.13264012336731s of computation time...\n",
      "More than 51.14307141304016s of computation time...\n",
      "More than 51.15343737602234s of computation time...\n",
      "More than 51.16384696960449s of computation time...\n",
      "More than 51.17469930648804s of computation time...\n",
      "More than 51.185086727142334s of computation time...\n",
      "More than 51.19548749923706s of computation time...\n",
      "More than 51.20588660240173s of computation time...\n",
      "More than 51.21628189086914s of computation time...\n",
      "More than 51.2266685962677s of computation time...\n",
      "More than 51.23705458641052s of computation time...\n",
      "More than 51.24747037887573s of computation time...\n",
      "More than 51.25798583030701s of computation time...\n",
      "More than 51.268439292907715s of computation time...\n",
      "More than 51.27893567085266s of computation time...\n",
      "More than 51.28945970535278s of computation time...\n",
      "More than 51.300129890441895s of computation time...\n",
      "More than 51.31043457984924s of computation time...\n",
      "More than 51.32079005241394s of computation time...\n",
      "More than 51.331204652786255s of computation time...\n",
      "More than 51.3415470123291s of computation time...\n",
      "More than 51.35191082954407s of computation time...\n",
      "More than 51.3622567653656s of computation time...\n",
      "More than 51.372689723968506s of computation time...\n",
      "More than 51.38301205635071s of computation time...\n",
      "More than 51.39343810081482s of computation time...\n",
      "More than 51.40383958816528s of computation time...\n",
      "More than 51.41433596611023s of computation time...\n",
      "More than 51.424649477005005s of computation time...\n",
      "More than 51.4349639415741s of computation time...\n",
      "More than 51.445645570755005s of computation time...\n",
      "More than 51.456132888793945s of computation time...\n",
      "More than 51.46649169921875s of computation time...\n",
      "More than 51.47689175605774s of computation time...\n",
      "More than 51.48741817474365s of computation time...\n",
      "More than 51.49781775474548s of computation time...\n",
      "More than 51.508201599121094s of computation time...\n",
      "More than 51.5191113948822s of computation time...\n",
      "More than 51.52950310707092s of computation time...\n",
      "More than 51.539851903915405s of computation time...\n",
      "More than 51.550360679626465s of computation time...\n",
      "More than 51.56091094017029s of computation time...\n",
      "More than 51.571428298950195s of computation time...\n",
      "More than 51.58184838294983s of computation time...\n",
      "More than 51.59221410751343s of computation time...\n",
      "More than 51.60270857810974s of computation time...\n",
      "More than 51.6131477355957s of computation time...\n",
      "More than 51.62361931800842s of computation time...\n",
      "More than 51.63396143913269s of computation time...\n",
      "More than 51.64434361457825s of computation time...\n",
      "More than 51.65490937232971s of computation time...\n",
      "More than 51.66533875465393s of computation time...\n",
      "More than 51.67567992210388s of computation time...\n",
      "More than 51.686129331588745s of computation time...\n",
      "More than 51.696789503097534s of computation time...\n",
      "More than 51.707149028778076s of computation time...\n",
      "More than 51.71766209602356s of computation time...\n",
      "More than 51.7280695438385s of computation time...\n",
      "More than 51.73846673965454s of computation time...\n",
      "More than 51.74885845184326s of computation time...\n",
      "More than 51.75922226905823s of computation time...\n",
      "More than 51.7696738243103s of computation time...\n",
      "More than 51.78004693984985s of computation time...\n",
      "More than 51.790438413619995s of computation time...\n",
      "More than 51.80082321166992s of computation time...\n",
      "More than 51.81124806404114s of computation time...\n",
      "More than 51.8216655254364s of computation time...\n",
      "More than 51.83195662498474s of computation time...\n",
      "More than 51.8422315120697s of computation time...\n",
      "More than 51.85257840156555s of computation time...\n",
      "More than 51.86297821998596s of computation time...\n",
      "More than 51.873270750045776s of computation time...\n",
      "More than 51.883662700653076s of computation time...\n",
      "More than 51.894086837768555s of computation time...\n",
      "More than 51.90501666069031s of computation time...\n",
      "More than 51.91547894477844s of computation time...\n",
      "More than 51.925848960876465s of computation time...\n",
      "More than 51.9362313747406s of computation time...\n",
      "More than 51.946697473526s of computation time...\n",
      "More than 51.957093238830566s of computation time...\n",
      "More than 51.96749210357666s of computation time...\n",
      "More than 51.977781534194946s of computation time...\n",
      "More than 51.98808240890503s of computation time...\n",
      "More than 51.9984290599823s of computation time...\n",
      "More than 52.00874948501587s of computation time...\n",
      "More than 52.01916170120239s of computation time...\n",
      "More than 52.02955412864685s of computation time...\n",
      "More than 52.03993058204651s of computation time...\n",
      "More than 52.05035877227783s of computation time...\n",
      "More than 52.06066632270813s of computation time...\n",
      "More than 52.07109832763672s of computation time...\n",
      "More than 52.0814368724823s of computation time...\n",
      "More than 52.09176516532898s of computation time...\n",
      "More than 52.10213589668274s of computation time...\n",
      "More than 52.11255216598511s of computation time...\n",
      "More than 52.12328600883484s of computation time...\n",
      "More than 52.13361835479736s of computation time...\n",
      "More than 52.14400601387024s of computation time...\n",
      "More than 52.15444612503052s of computation time...\n",
      "More than 52.164884090423584s of computation time...\n",
      "More than 52.175273180007935s of computation time...\n",
      "More than 52.185784101486206s of computation time...\n",
      "More than 52.19618082046509s of computation time...\n",
      "More than 52.20704674720764s of computation time...\n",
      "More than 52.21737456321716s of computation time...\n",
      "More than 52.227869749069214s of computation time...\n",
      "More than 52.238369941711426s of computation time...\n",
      "More than 52.24868583679199s of computation time...\n",
      "More than 52.25910496711731s of computation time...\n",
      "More than 52.26943492889404s of computation time...\n",
      "More than 52.279820919036865s of computation time...\n",
      "More than 52.29011797904968s of computation time...\n",
      "More than 52.30046606063843s of computation time...\n",
      "More than 52.3108274936676s of computation time...\n",
      "More than 52.321157693862915s of computation time...\n",
      "More than 52.33171534538269s of computation time...\n",
      "More than 52.34209728240967s of computation time...\n",
      "More than 52.35255408287048s of computation time...\n",
      "More than 52.36296463012695s of computation time...\n",
      "More than 52.373326539993286s of computation time...\n",
      "More than 52.383644819259644s of computation time...\n",
      "More than 52.39400792121887s of computation time...\n",
      "More than 52.4043664932251s of computation time...\n",
      "More than 52.414719343185425s of computation time...\n",
      "More than 52.42509055137634s of computation time...\n",
      "More than 52.4356255531311s of computation time...\n",
      "More than 52.44610095024109s of computation time...\n",
      "More than 52.45653057098389s of computation time...\n",
      "More than 52.46691060066223s of computation time...\n",
      "More than 52.477256536483765s of computation time...\n",
      "More than 52.48768997192383s of computation time...\n",
      "More than 52.498034954071045s of computation time...\n",
      "More than 52.50845503807068s of computation time...\n",
      "More than 52.51884198188782s of computation time...\n",
      "More than 52.529173851013184s of computation time...\n",
      "More than 52.53959941864014s of computation time...\n",
      "More than 52.54998421669006s of computation time...\n",
      "More than 52.56036448478699s of computation time...\n",
      "More than 52.57080101966858s of computation time...\n",
      "More than 52.58146834373474s of computation time...\n",
      "More than 52.59217381477356s of computation time...\n",
      "More than 52.602513551712036s of computation time...\n",
      "More than 52.61328101158142s of computation time...\n",
      "More than 52.623663663864136s of computation time...\n",
      "More than 52.633978843688965s of computation time...\n",
      "More than 52.644354820251465s of computation time...\n",
      "More than 52.65463995933533s of computation time...\n",
      "More than 52.66500401496887s of computation time...\n",
      "More than 52.67532205581665s of computation time...\n",
      "More than 52.68567371368408s of computation time...\n",
      "More than 52.69608449935913s of computation time...\n",
      "More than 52.70683717727661s of computation time...\n",
      "More than 52.717159271240234s of computation time...\n",
      "More than 52.72753167152405s of computation time...\n",
      "More than 52.73797941207886s of computation time...\n",
      "More than 52.748374938964844s of computation time...\n",
      "More than 52.75874400138855s of computation time...\n",
      "More than 52.76934862136841s of computation time...\n",
      "More than 52.779813289642334s of computation time...\n",
      "More than 52.79022550582886s of computation time...\n",
      "More than 52.80064606666565s of computation time...\n",
      "More than 52.811039686203s of computation time...\n",
      "More than 52.821534872055054s of computation time...\n",
      "More than 52.83184480667114s of computation time...\n",
      "More than 52.84273886680603s of computation time...\n",
      "More than 52.85310387611389s of computation time...\n",
      "More than 52.86351466178894s of computation time...\n",
      "More than 52.87386441230774s of computation time...\n",
      "More than 52.88425016403198s of computation time...\n",
      "More than 52.89460515975952s of computation time...\n",
      "More than 52.90494680404663s of computation time...\n",
      "More than 52.91526389122009s of computation time...\n",
      "More than 52.92562532424927s of computation time...\n",
      "More than 52.936020851135254s of computation time...\n",
      "More than 52.94646096229553s of computation time...\n",
      "More than 52.95682907104492s of computation time...\n",
      "More than 52.96735739707947s of computation time...\n",
      "More than 52.97790741920471s of computation time...\n",
      "More than 52.988269329071045s of computation time...\n",
      "More than 52.998584032058716s of computation time...\n",
      "More than 53.00895881652832s of computation time...\n",
      "More than 53.01933002471924s of computation time...\n",
      "More than 53.029685735702515s of computation time...\n",
      "More than 53.040000438690186s of computation time...\n",
      "More than 53.05033612251282s of computation time...\n",
      "More than 53.06067657470703s of computation time...\n",
      "More than 53.07102656364441s of computation time...\n",
      "More than 53.08137893676758s of computation time...\n",
      "More than 53.09175777435303s of computation time...\n",
      "More than 53.10211777687073s of computation time...\n",
      "More than 53.11245274543762s of computation time...\n",
      "More than 53.1227924823761s of computation time...\n",
      "More than 53.13313126564026s of computation time...\n",
      "More than 53.143484115600586s of computation time...\n",
      "More than 53.15387964248657s of computation time...\n",
      "More than 53.16431260108948s of computation time...\n",
      "More than 53.17474985122681s of computation time...\n",
      "More than 53.18523025512695s of computation time...\n",
      "More than 53.19559621810913s of computation time...\n",
      "More than 53.2059760093689s of computation time...\n",
      "More than 53.21642589569092s of computation time...\n",
      "More than 53.226930141448975s of computation time...\n",
      "More than 53.23727083206177s of computation time...\n",
      "More than 53.24777817726135s of computation time...\n",
      "More than 53.25810503959656s of computation time...\n",
      "More than 53.26848864555359s of computation time...\n",
      "More than 53.27879309654236s of computation time...\n",
      "More than 53.28919696807861s of computation time...\n",
      "More than 53.299633264541626s of computation time...\n",
      "More than 53.310550928115845s of computation time...\n",
      "More than 53.3208692073822s of computation time...\n",
      "More than 53.331254720687866s of computation time...\n",
      "More than 53.341729402542114s of computation time...\n",
      "More than 53.352174520492554s of computation time...\n",
      "More than 53.362608909606934s of computation time...\n",
      "More than 53.373006105422974s of computation time...\n",
      "More than 53.383512020111084s of computation time...\n",
      "More than 53.39387083053589s of computation time...\n",
      "More than 53.404218912124634s of computation time...\n",
      "More than 53.415194272994995s of computation time...\n",
      "More than 53.425588846206665s of computation time...\n",
      "More than 53.43591809272766s of computation time...\n",
      "More than 53.44630479812622s of computation time...\n",
      "More than 53.456610441207886s of computation time...\n",
      "More than 53.46720576286316s of computation time...\n",
      "More than 53.477538108825684s of computation time...\n",
      "More than 53.4879584312439s of computation time...\n",
      "More than 53.49858045578003s of computation time...\n",
      "More than 53.508944272994995s of computation time...\n",
      "More than 53.51926779747009s of computation time...\n",
      "More than 53.52961730957031s of computation time...\n",
      "More than 53.54001760482788s of computation time...\n",
      "More than 53.55041766166687s of computation time...\n",
      "More than 53.56080627441406s of computation time...\n",
      "More than 53.57133507728577s of computation time...\n",
      "More than 53.581725120544434s of computation time...\n",
      "More than 53.59213042259216s of computation time...\n",
      "More than 53.60253071784973s of computation time...\n",
      "More than 53.61287045478821s of computation time...\n",
      "More than 53.62320423126221s of computation time...\n",
      "More than 53.633593797683716s of computation time...\n",
      "More than 53.64390802383423s of computation time...\n",
      "More than 53.65424561500549s of computation time...\n",
      "More than 53.66461157798767s of computation time...\n",
      "More than 53.674968242645264s of computation time...\n",
      "More than 53.685314655303955s of computation time...\n",
      "More than 53.69569373130798s of computation time...\n",
      "More than 53.706082344055176s of computation time...\n",
      "More than 53.71690058708191s of computation time...\n",
      "More than 53.727226972579956s of computation time...\n",
      "More than 53.73757576942444s of computation time...\n",
      "More than 53.7481586933136s of computation time...\n",
      "More than 53.75880789756775s of computation time...\n",
      "More than 53.769217014312744s of computation time...\n",
      "More than 53.779659271240234s of computation time...\n",
      "More than 53.79002857208252s of computation time...\n",
      "More than 53.80049777030945s of computation time...\n",
      "More than 53.81078624725342s of computation time...\n",
      "More than 53.82116746902466s of computation time...\n",
      "More than 53.83167743682861s of computation time...\n",
      "More than 53.84203600883484s of computation time...\n",
      "More than 53.852415323257446s of computation time...\n",
      "More than 53.86291217803955s of computation time...\n",
      "More than 53.87330436706543s of computation time...\n",
      "More than 53.883745431900024s of computation time...\n",
      "More than 53.89407253265381s of computation time...\n",
      "More than 53.9044668674469s of computation time...\n",
      "More than 53.914854764938354s of computation time...\n",
      "More than 53.92517566680908s of computation time...\n",
      "More than 53.93554091453552s of computation time...\n",
      "More than 53.94639539718628s of computation time...\n",
      "More than 53.957518577575684s of computation time...\n",
      "More than 53.96811056137085s of computation time...\n",
      "More than 53.97854256629944s of computation time...\n",
      "More than 53.98891615867615s of computation time...\n",
      "More than 53.99935507774353s of computation time...\n",
      "More than 54.009745836257935s of computation time...\n",
      "More than 54.02013182640076s of computation time...\n",
      "More than 54.030858278274536s of computation time...\n",
      "More than 54.041313886642456s of computation time...\n",
      "More than 54.05162501335144s of computation time...\n",
      "More than 54.061981201171875s of computation time...\n",
      "More than 54.07245230674744s of computation time...\n",
      "More than 54.082844257354736s of computation time...\n",
      "More than 54.0931670665741s of computation time...\n",
      "More than 54.103498220443726s of computation time...\n",
      "More than 54.11383891105652s of computation time...\n",
      "More than 54.124199867248535s of computation time...\n",
      "More than 54.134541034698486s of computation time...\n",
      "More than 54.14483404159546s of computation time...\n",
      "More than 54.15524244308472s of computation time...\n",
      "More than 54.16555118560791s of computation time...\n",
      "More than 54.175873041152954s of computation time...\n",
      "More than 54.18632888793945s of computation time...\n",
      "More than 54.19670391082764s of computation time...\n",
      "More than 54.20714855194092s of computation time...\n",
      "More than 54.21760845184326s of computation time...\n",
      "More than 54.22792363166809s of computation time...\n",
      "More than 54.23843216896057s of computation time...\n",
      "More than 54.248769760131836s of computation time...\n",
      "More than 54.2591609954834s of computation time...\n",
      "More than 54.26980972290039s of computation time...\n",
      "More than 54.280396699905396s of computation time...\n",
      "More than 54.29074239730835s of computation time...\n",
      "More than 54.301172971725464s of computation time...\n",
      "More than 54.31155347824097s of computation time...\n",
      "More than 54.321988582611084s of computation time...\n",
      "More than 54.332401514053345s of computation time...\n",
      "More than 54.34277319908142s of computation time...\n",
      "More than 54.35315227508545s of computation time...\n",
      "More than 54.36390829086304s of computation time...\n",
      "More than 54.37424564361572s of computation time...\n",
      "More than 54.384708404541016s of computation time...\n",
      "More than 54.39510488510132s of computation time...\n",
      "More than 54.40547204017639s of computation time...\n",
      "More than 54.415905475616455s of computation time...\n",
      "More than 54.42633008956909s of computation time...\n",
      "More than 54.43671464920044s of computation time...\n",
      "More than 54.44721436500549s of computation time...\n",
      "More than 54.457605838775635s of computation time...\n",
      "More than 54.4679114818573s of computation time...\n",
      "More than 54.478212118148804s of computation time...\n",
      "More than 54.48867607116699s of computation time...\n",
      "More than 54.49910640716553s of computation time...\n",
      "More than 54.50965595245361s of computation time...\n",
      "More than 54.52012896537781s of computation time...\n",
      "More than 54.53070044517517s of computation time...\n",
      "More than 54.54105091094971s of computation time...\n",
      "More than 54.55151057243347s of computation time...\n",
      "More than 54.561840772628784s of computation time...\n",
      "More than 54.572450160980225s of computation time...\n",
      "More than 54.582929372787476s of computation time...\n",
      "More than 54.59329152107239s of computation time...\n",
      "More than 54.60374879837036s of computation time...\n",
      "More than 54.61411190032959s of computation time...\n",
      "More than 54.62448978424072s of computation time...\n",
      "More than 54.63489294052124s of computation time...\n",
      "More than 54.64526295661926s of computation time...\n",
      "More than 54.655624866485596s of computation time...\n",
      "More than 54.666088819503784s of computation time...\n",
      "More than 54.67643880844116s of computation time...\n",
      "More than 54.68679690361023s of computation time...\n",
      "More than 54.69713878631592s of computation time...\n",
      "More than 54.7075092792511s of computation time...\n",
      "More than 54.71787643432617s of computation time...\n",
      "More than 54.7282338142395s of computation time...\n",
      "More than 54.73885202407837s of computation time...\n",
      "More than 54.74913048744202s of computation time...\n",
      "More than 54.75961375236511s of computation time...\n",
      "More than 54.76990818977356s of computation time...\n",
      "More than 54.78027939796448s of computation time...\n",
      "More than 54.790785789489746s of computation time...\n",
      "More than 54.801119804382324s of computation time...\n",
      "More than 54.811519384384155s of computation time...\n",
      "More than 54.8218469619751s of computation time...\n",
      "More than 54.83225083351135s of computation time...\n",
      "More than 54.84257888793945s of computation time...\n",
      "More than 54.8530216217041s of computation time...\n",
      "More than 54.86343479156494s of computation time...\n",
      "More than 54.873799324035645s of computation time...\n",
      "More than 54.88418769836426s of computation time...\n",
      "More than 54.89483642578125s of computation time...\n",
      "More than 54.90542221069336s of computation time...\n",
      "More than 54.9157989025116s of computation time...\n",
      "More than 54.92625069618225s of computation time...\n",
      "More than 54.936596632003784s of computation time...\n",
      "More than 54.94693064689636s of computation time...\n",
      "More than 54.95733880996704s of computation time...\n",
      "More than 54.967767000198364s of computation time...\n",
      "More than 54.97810077667236s of computation time...\n",
      "More than 54.9885196685791s of computation time...\n",
      "More than 54.99893617630005s of computation time...\n",
      "More than 55.009599447250366s of computation time...\n",
      "More than 55.0200412273407s of computation time...\n",
      "More than 55.0304958820343s of computation time...\n",
      "More than 55.04100728034973s of computation time...\n",
      "More than 55.05142116546631s of computation time...\n",
      "More than 55.06192207336426s of computation time...\n",
      "More than 55.072293519973755s of computation time...\n",
      "More than 55.082717180252075s of computation time...\n",
      "More than 55.093127727508545s of computation time...\n",
      "More than 55.10352349281311s of computation time...\n",
      "More than 55.11387872695923s of computation time...\n",
      "More than 55.12417459487915s of computation time...\n",
      "More than 55.134522676467896s of computation time...\n",
      "More than 55.14493441581726s of computation time...\n",
      "More than 55.155399322509766s of computation time...\n",
      "More than 55.165716886520386s of computation time...\n",
      "More than 55.17603421211243s of computation time...\n",
      "More than 55.18649196624756s of computation time...\n",
      "More than 55.19691514968872s of computation time...\n",
      "More than 55.207204818725586s of computation time...\n",
      "More than 55.21766757965088s of computation time...\n",
      "More than 55.22806644439697s of computation time...\n",
      "More than 55.2384135723114s of computation time...\n",
      "More than 55.24884343147278s of computation time...\n",
      "More than 55.259246587753296s of computation time...\n",
      "More than 55.26968312263489s of computation time...\n",
      "More than 55.28017473220825s of computation time...\n",
      "More than 55.290560245513916s of computation time...\n",
      "More than 55.30111861228943s of computation time...\n",
      "More than 55.31147050857544s of computation time...\n",
      "More than 55.32205390930176s of computation time...\n",
      "More than 55.33244872093201s of computation time...\n",
      "More than 55.34531497955322s of computation time...\n",
      "More than 55.35587954521179s of computation time...\n",
      "More than 55.36635684967041s of computation time...\n",
      "More than 55.37679576873779s of computation time...\n",
      "More than 55.38711977005005s of computation time...\n",
      "More than 55.39754796028137s of computation time...\n",
      "More than 55.407869815826416s of computation time...\n",
      "More than 55.41838502883911s of computation time...\n",
      "More than 55.42873024940491s of computation time...\n",
      "More than 55.4391565322876s of computation time...\n",
      "More than 55.44961929321289s of computation time...\n",
      "More than 55.460026025772095s of computation time...\n",
      "More than 55.470499753952026s of computation time...\n",
      "More than 55.48087286949158s of computation time...\n",
      "More than 55.49135065078735s of computation time...\n",
      "More than 55.501787424087524s of computation time...\n",
      "More than 55.51211214065552s of computation time...\n",
      "More than 55.522494316101074s of computation time...\n",
      "More than 55.532856702804565s of computation time...\n",
      "More than 55.543190002441406s of computation time...\n",
      "More than 55.55351281166077s of computation time...\n",
      "More than 55.56383752822876s of computation time...\n",
      "More than 55.574249267578125s of computation time...\n",
      "More than 55.58509540557861s of computation time...\n",
      "More than 55.59540390968323s of computation time...\n",
      "More than 55.60576009750366s of computation time...\n",
      "More than 55.6161744594574s of computation time...\n",
      "More than 55.62653350830078s of computation time...\n",
      "More than 55.63713526725769s of computation time...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cc42c2f0ddf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"More than {}s of computation time...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36m_is_master_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_master_pid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "total_words_in_all_data = 0\n",
    "for index in range(0, len(dataset)):\n",
    "    total_words_in_all_data = total_words_in_all_data + count_word_in_statement(dataset[index])\n",
    "    end = time.time() - start\n",
    "    if end >= 50:\n",
    "        print(\"More than {}s of computation time...\".format(end))\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42527 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = Client() #change your setting 'dask-scheduler:8786'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word in the dataset: 2038444\n",
      "Computation took 34.86036252975464s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "futures = [client.submit(count_word_in_statement, data) for data in dataset]\n",
    "futures = client.submit(sum, futures)\n",
    "total_words_in_all_data = client.gather(futures)\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we increment the number of workers or threads per worker?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you feel like a hero and you don't be afraid to become old by standing in front of the PC, you can try to compare the sequential code and the distributed code by increasing the sleep time 100ms or 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How works the distribution and the scheduling of the processes?\n",
    "\n",
    "#### How a worker is choosen?\n",
    "Even though you can reduce and make some restrictions, e.g: restriction over worker resources, Dask automatically decides the suitable workers for your tasks by figuring out the optimized worker for each task.\n",
    "This means that, if a task has significant data dependencies or if the workers are under heavy load then this choice of worker can strongly impact global performance because the decision becomes heavy.\n",
    "\n",
    "Dask follows the following rules before to assign a task to a worker:\n",
    "+ If the task has no major dependencies and no restrictions then we find the least occupied worker.\n",
    "\n",
    "+ if a task has user-provided restrictions (for example it must run on a machine with a GPU) then we restrict the available pool of workers to just that set, otherwise, we consider all workers\n",
    "+ from the pool of workers Dask determinates the workers to whom the least amount of data would need to be transferred (means less overhead on the cluster and hence computation optimization).\n",
    "+  if some dependencies in the graph can be broken the will be assigned to the worker that currently has the fewest tasks.\n",
    "\n",
    "\n",
    "Dask also allows modifying the worker decision function in order to be more flexible and to improve the customization of a cluster. This means that particular processes or particular computational fields in which performances can be improved by customizing and optimizing the task's assignation decision can be made more performant.\n",
    "\n",
    "Breaking the dependencies in some cases is necessary, especially if each node has a lot of sons. In this case, each node with his sons must be removed from the graph and computed alone. This has a huge impact on performances and memory. On the other hand, this means that when a user submits a task, the computation graph must be scan to figuring out and optimizing this kind of dependencies.\n",
    "\n",
    "\n",
    "#### How choose the next task?\n",
    "Typically Dask follows those rules in order to choose the next task that must be executed:\n",
    "+ Run tasks on a first-come-first-served basis for fairness between multiple clients\n",
    "+ Run tasks that are part of the critical path in an effort to reduce total running time and minimize straggler workloads\n",
    "+ Run tasks that allow us to release many dependencies in an effort to keep the memory footprint small\n",
    "+ Run tasks that are related so that large chunks of work can be completely eliminated before running new chunks of work\n",
    "\n",
    "As you can see a part of the overhead on a cluster is principally caused by the optimization of the execution task decision. Even though these are rules implemented by Dask, in general, the majority of the Cluster, even if they are based on other frameworks and other architectures, follow the same similar approaches.\n",
    "\n",
    "On the other hand, some computational fields may require a different approach to decide which tasks can be executed, e.g: by using last-in-first-out approach or by giving a priority to each task in order to execute first some processes.\n",
    "\n",
    "In some cases, Dask optimization exploit also a partially last-in-first-out approach. When a worker finishes a task the immediate dependencies of that task get top priority. This encourages a behavior of finishing ongoing work immediately before starting new work. This often conflicts with the first-come-first-served objective but often results in shorter total runtimes and significantly reduced memory footprints.\n",
    "\n",
    "\n",
    "#### Where these decisions are made?\n",
    "\n",
    "The decision are basically made ina small steps and in a different computation steps by client, scheduler, and workers:\n",
    "\n",
    "+ As we submit a graph from the *client* to the scheduler we automatically assign a numeric priority to each task of that graph. This priority focuses on computing deeply before broadly, preferring critical paths, and preferring nodes with many dependencies.\n",
    "\n",
    "+ When the graph reaches the scheduler the scheduler changes each of these numeric priorities into a tuple of two numbers, the first of which is an increasing counter, the second of which is the client-generated priority described above. This per-graph counter encourages a first-in-first-out policy between computations. All tasks from a previous call to compute have a higher priority than all tasks from a subsequent call to compute (or submit, persist, map, or any operation that generates futures).\n",
    "\n",
    "+ Whenever a task is ready to run the scheduler assigns it to a worker. The scheduler does not wait based on priority. However when the worker receives these tasks it considers their priorities when determining which tasks to prioritize for communication or for computation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker Resources\n",
    "\n",
    "Let's suppose that you want to run a proces over a cluster, but only in those machine that has a GPU or have at least 16Gb of RAM. Now let's imagin that you have a cluster of ten computers in which four have a GPU while the others no. In this case we want to balance tasks across the cluster with these resource constraints in mind, allocating GPU-constrained tasks to GPU-enabled workers. Additionally we need to be sure to constrain the number of GPU tasks that run concurrently on any given worker to ensure that we respect the provided limits.\n",
    "Clearly, this situation arises not only for GPUs but for many resources like tasks that require a large amount of memory at runtime, special disk access, or access to special hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you require workers with particular resources you must be sure that those resources are availables over the cluster.\n",
    "Otherwise your processes should be never executed.\n",
    "\n",
    "Let's try an example togheter: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, stop the workers that you have in your cluster and the scheduler. Start again the scheduler and then turn up two workers with those commands:\n",
    "\n",
    "+ ```dask-worker dask-scheduler:8786 --nprocs 1 --nthreads 1 --resources \"GPU=2\"```\n",
    "+ ```dask-worker dask-scheduler:8786 --nprocs 1 --nthreads 1 --resources \"GPU=1\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "client = Client() ##change your settings 'dask-scheduler:8786'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:36703</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>5.82 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:36703' processes=4 threads=4, memory=5.82 GiB>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = []\n",
    "\n",
    "for i in range(100):\n",
    "    matrices.append(np.random.rand(4,3))\n",
    "\n",
    "def compute_polynomial_kernel(matrix):\n",
    "    polynomial_degree = 2\n",
    "    return np.power((np.dot(matrix, matrix.T)+1), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working on a matrix computation let's suppose that we want exploit the multi-gpu available only on some workers. \n",
    "Assume that we need to use 3 GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9aabdbdf2650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_polynomial_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatrices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mkernels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1973\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m                 \u001b[0mlocal_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1975\u001b[0;31m             return self.sync(\n\u001b[0m\u001b[1;32m   1976\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m                 \u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             return sync(\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "processed = [client.submit(compute_polynomial_kernel, matrix, resources={'GPU': 3}) for matrix in matrices]\n",
    "\n",
    "kernels = client.gather(processed)\n",
    "\n",
    "for i in kernels:\n",
    "    print(\"Kernel is: {}\".format(i))\n",
    "    print()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nothing is happening but the code still running...... Let's try to add on-the-fly a worker with 3 GPUs\n",
    "\n",
    "```dask-worker 192.168.1.12:8786 --nprocs 1 --nthreads 1 --resources \"GPU=3\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Compute the traces of all the generated matrix. Execute this code over 2 workers with 2 \"SpecialCPU\" each one.\n",
    "You must use the ```map``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = [np.random.randint(low=m, high=m+1, size=(4, 3)) for m in (range(11))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "Execute the code of the \"howmany_within_range\" exercise from the previous lecture, into a worker with 256Gb of RAM. Map function is not allowed.\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
