{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line\n",
    "\n",
    "\n",
    "This is the most fundamental way to deploy Dask on multiple machines. In production environments, this process is often automated by some other resource manager. Hence, it is rare that people need to follow these instructions explicitly. But since we want learn how to \"build\" a cluster we want study how to start it from the command line.\n",
    "\n",
    "A ```dask.distributed``` network consists of one ```dask-scheduler``` process and several ```dask-worker``` processes that connect to that scheduler. These are normal Python processes that can be executed from the command line. We launch the dask-scheduler executable in one process and the dask-worker executable in several processes, possibly on different machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, respect to the revious lectures, today we want to create a cluster \"from scratch\" using IP addresses and real workers and not the automatic \"local cluster\" created by dask.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first let's see how works the ```dask-scheduler``` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: dask-scheduler [OPTIONS] [PRELOAD_ARGV]...\n",
      "\n",
      "Options:\n",
      "  --host TEXT                   URI, IP or hostname of this server\n",
      "  --port INTEGER                Serving port\n",
      "  --interface TEXT              Preferred network interface like 'eth0' or\n",
      "                                'ib0'\n",
      "\n",
      "  --protocol TEXT               Protocol like tcp, tls, or ucx\n",
      "  --tls-ca-file PATH            CA cert(s) file for TLS (in PEM format)\n",
      "  --tls-cert PATH               certificate file for TLS (in PEM format)\n",
      "  --tls-key PATH                private key file for TLS (in PEM format)\n",
      "  --bokeh-port INTEGER          Deprecated.  See --dashboard-address\n",
      "  --dashboard-address TEXT      Address on which to listen for diagnostics\n",
      "                                dashboard  [default: :8787]\n",
      "\n",
      "  --dashboard / --no-dashboard  Launch the Dashboard [default: --dashboard]\n",
      "  --bokeh / --no-bokeh          Deprecated.  See --dashboard/--no-dashboard.\n",
      "  --show / --no-show            Show web UI [default: --show]\n",
      "  --dashboard-prefix TEXT       Prefix for the dashboard app\n",
      "  --use-xheaders BOOLEAN        User xheaders in dashboard app for ssl\n",
      "                                termination in header  [default: False]\n",
      "\n",
      "  --pid-file TEXT               File to write the process PID\n",
      "  --scheduler-file TEXT         File to write connection information. This may\n",
      "                                be a good way to share connection information\n",
      "                                if your cluster is on a shared network file\n",
      "                                system.\n",
      "\n",
      "  --preload TEXT                Module that should be loaded by the scheduler\n",
      "                                process  like \"foo.bar\" or \"/path/to/foo.py\".\n",
      "\n",
      "  --idle-timeout TEXT           Time of inactivity after which to kill the\n",
      "                                scheduler\n",
      "\n",
      "  --version                     Show the version and exit.\n",
      "  --help                        Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "dask-scheduler --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "#dask-scheduler run it inside a real bash terminal not from jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command ```dask-worker``` on the rest of the nodes. Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: dask-worker [OPTIONS] [SCHEDULER] [PRELOAD_ARGV]...\n",
      "\n",
      "Options:\n",
      "  --tls-ca-file PATH              CA cert(s) file for TLS (in PEM format)\n",
      "  --tls-cert PATH                 certificate file for TLS (in PEM format)\n",
      "  --tls-key PATH                  private key file for TLS (in PEM format)\n",
      "  --worker-port TEXT              Serving computation port, defaults to\n",
      "                                  random. When creating multiple workers with\n",
      "                                  --nprocs, a sequential range of worker ports\n",
      "                                  may be used by specifying the first and last\n",
      "                                  available ports like <first-port>:<last-\n",
      "                                  port>. For example, --worker-port=3000:3026\n",
      "                                  will use ports 3000, 3001, ..., 3025, 3026.\n",
      "\n",
      "  --nanny-port TEXT               Serving nanny port, defaults to random. When\n",
      "                                  creating multiple nannies with --nprocs, a\n",
      "                                  sequential range of nanny ports may be used\n",
      "                                  by specifying the first and last available\n",
      "                                  ports like <first-port>:<last-port>. For\n",
      "                                  example, --nanny-port=3000:3026 will use\n",
      "                                  ports 3000, 3001, ..., 3025, 3026.\n",
      "\n",
      "  --bokeh-port INTEGER            Deprecated.  See --dashboard-address\n",
      "  --dashboard-address TEXT        Address on which to listen for diagnostics\n",
      "                                  dashboard\n",
      "\n",
      "  --dashboard / --no-dashboard    Launch the Dashboard [default: --dashboard]\n",
      "  --bokeh / --no-bokeh            Deprecated.  See --dashboard/--no-dashboard.\n",
      "  --listen-address TEXT           The address to which the worker binds.\n",
      "                                  Example: tcp://0.0.0.0:9000\n",
      "\n",
      "  --contact-address TEXT          The address the worker advertises to the\n",
      "                                  scheduler for communication with it and\n",
      "                                  other workers. Example: tcp://127.0.0.1:9000\n",
      "\n",
      "  --host TEXT                     Serving host. Should be an ip address that\n",
      "                                  is visible to the scheduler and other\n",
      "                                  workers. See --listen-address and --contact-\n",
      "                                  address if you need different listen and\n",
      "                                  contact addresses. See --interface.\n",
      "\n",
      "  --interface TEXT                Network interface like 'eth0' or 'ib0'\n",
      "  --protocol TEXT                 Protocol like tcp, tls, or ucx\n",
      "  --nthreads INTEGER              Number of threads per process.\n",
      "  --nprocs TEXT                   Number of worker processes to launch. If\n",
      "                                  negative, then (CPU_COUNT + 1 + nprocs) is\n",
      "                                  used. Set to 'auto' to set nprocs and\n",
      "                                  nthreads dynamically based on CPU_COUNT\n",
      "                                  [default: 1]\n",
      "\n",
      "  --name TEXT                     A unique name for this worker like\n",
      "                                  'worker-1'. If used with --nprocs then the\n",
      "                                  process number will be appended like name-0,\n",
      "                                  name-1, name-2, ...\n",
      "\n",
      "  --memory-limit TEXT             Bytes of memory per process that the worker can use.\n",
      "                                  This can be:\n",
      "                                  - an integer (bytes), note 0 is a special case for no memory management.\n",
      "                                  - a float (fraction of total system memory).\n",
      "                                  - a string (like 5GB or 5000M).\n",
      "                                  - 'auto' for automatically computing the memory limit.  [default: auto]\n",
      "\n",
      "  --reconnect / --no-reconnect    Reconnect to scheduler if disconnected\n",
      "                                  [default: --reconnect]\n",
      "\n",
      "  --nanny / --no-nanny            Start workers in nanny process for\n",
      "                                  management [default: --nanny]\n",
      "\n",
      "  --pid-file TEXT                 File to write the process PID\n",
      "  --local-directory TEXT          Directory to place worker files\n",
      "  --resources TEXT                Resources for task constraints like \"GPU=2\n",
      "                                  MEM=10e9\". Resources are applied separately\n",
      "                                  to each worker process (only relevant when\n",
      "                                  starting multiple worker processes with '--\n",
      "                                  nprocs').\n",
      "\n",
      "  --scheduler-file TEXT           Filename to JSON encoded scheduler\n",
      "                                  information. Use with dask-scheduler\n",
      "                                  --scheduler-file\n",
      "\n",
      "  --death-timeout TEXT            Seconds to wait for a scheduler before\n",
      "                                  closing\n",
      "\n",
      "  --dashboard-prefix TEXT         Prefix for the dashboard\n",
      "  --lifetime TEXT                 If provided, shut down the worker after this\n",
      "                                  duration.\n",
      "\n",
      "  --lifetime-stagger TEXT         Random amount by which to stagger lifetime\n",
      "                                  values  [default: 0 seconds]\n",
      "\n",
      "  --worker-class TEXT             Worker class used to instantiate workers\n",
      "                                  from.  [default: dask.distributed.Worker]\n",
      "\n",
      "  --lifetime-restart / --no-lifetime-restart\n",
      "                                  Whether or not to restart the worker after\n",
      "                                  the lifetime lapses. This assumes that you\n",
      "                                  are using the --lifetime and --nanny\n",
      "                                  keywords  [default: False]\n",
      "\n",
      "  --preload TEXT                  Module that should be loaded by each worker\n",
      "                                  process like \"foo.bar\" or \"/path/to/foo.py\"\n",
      "\n",
      "  --preload-nanny TEXT            Module that should be loaded by each nanny\n",
      "                                  like \"foo.bar\" or \"/path/to/foo.py\"\n",
      "\n",
      "  --version                       Show the version and exit.\n",
      "  --help                          Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "dask-worker --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thisn command must be run by providing the address to the node that hosts ```dask-scheduler```:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#dask-worker 192.168.1.12:8687 run int inside the real command line not from jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic concepts\n",
    "The scheduler and workers both need to accept TCP connections on an open port. By default, the scheduler binds to port 8786 and the worker binds to a random open port. If you are behind a firewall then you may have to open particular ports or tell Dask on a different port.\n",
    "\n",
    "Dask workers are run within a *nanny* process that *monitors* the worker process and restarts it if necessary.\n",
    "\n",
    "As we have saw last lecture, Dask schedulers and even workers host interactive diagnostic web servers using the Bokeh server. These are optional, but generally useful to users. The diagnostic server on the scheduler is particularly valuable, and is served on port 8787."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to create a your first cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first run the cell below in order to indentify your network-card and what your IP is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "ifconfig ##only for those of you that does not use the docker cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now open you command line and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask-scheduler --host IP --port 8786"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point open another command line and run this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask-worker IP:8786 --nprocs 2 #this command create 2 workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when is all up to date try to connect to the dashboard and take a look to your new cluster!\n",
    "If you have install all the packages in the correct way you should be able to access to the dashboard at: IP:8787"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an old exercise over the new cluster\n",
    "\n",
    "Try to count how many words are present in all the documents over the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts document present on the dataset: 8283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from dask.distributed import Client\n",
    "import time\n",
    "\n",
    "categories = [\n",
    "     'comp.graphics',\n",
    "     'comp.os.ms-windows.misc',\n",
    "     'comp.sys.ibm.pc.hardware',\n",
    "     'comp.sys.mac.hardware',\n",
    "     'comp.windows.x',\n",
    "     'misc.forsale',\n",
    "     'rec.autos',\n",
    "     'rec.motorcycles',\n",
    "     'rec.sport.baseball',\n",
    "     'rec.sport.hockey',\n",
    "     'sci.crypt',\n",
    "     'sci.electronics',\n",
    "     'sci.med',\n",
    "     'sci.space'\n",
    "]\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='train', categories=categories ).data\n",
    "\n",
    "print(\"Texts document present on the dataset: \"+str(len(dataset)))\n",
    "\n",
    "def count_word_in_statement(text):\n",
    "    \"\"\"\n",
    "    This function takes a text as input and return the number of the words that it contains\n",
    "    \"\"\"\n",
    "    #time.sleep(0.1)\n",
    "    splitted_words = text.split()\n",
    "    return len(splitted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word in the dataset: 2038444\n",
      "Computation took 0.21970582008361816s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "total_words_in_all_data = 0\n",
    "for index in range(0, len(dataset)):\n",
    "    total_words_in_all_data = total_words_in_all_data + count_word_in_statement(dataset[index])\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('dask-scheduler:8786') #change your setting 'dask-scheduler:8786'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word in the dataset: 2038444\n",
      "Computation took 14.78898000717163s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "#futures = client.map(count_word_in_statement, dataset)\n",
    "futures = [client.submit(count_word_in_statement, data) for data in dataset]\n",
    "\n",
    "futures = client.submit(sum, futures)\n",
    "total_words_in_all_data = client.gather(futures)\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why in this case sequential code took more than 10 times less than ditributed version?\n",
    "\n",
    "In general when yuo have to deal with a cluster you have to think about the *overhead* You can image the overhead like the the computational time necessary process your data. \n",
    "Typically in a cluster there two kind of overhead:\n",
    "+ scheduler overhead in serializing the objects that must be sent to workers\n",
    "+ connection overhead. The speed of the network connection between the cluster nodes\n",
    "\n",
    "In the first case, the scheduler adds about one millisecond of overhead per task or Future object. Despite this may sound fast or inconsequential, it's quite slow if you run a large number of tasks. Under this perspective, a larger number of the task means a larger amount of time to create the Future objects of the tasks. \n",
    "In the light of above, if your functions run faster than 100ms or so then you might not see any\n",
    "speedup from using distributed computing, but even worse, probably you might see that the performances get worse.\n",
    "\n",
    "In the second case things are different. The connection overhead may depends from several factors including the stability of the network, the type (wired or WiFi or optic fibe), and bandwith of the network.\n",
    "\n",
    "This is what is happening in the previous example.\n",
    "\n",
    "Let's try to introduce a simulation of intesive computation (a sleep of 10ms: 10 times less the the overhead generated by dask-scheduler):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_in_statement(text):\n",
    "    \"\"\"\n",
    "    This function takes a text as input and return the number of the words that it contains\n",
    "    \"\"\"\n",
    "    splitted_words = text.split()\n",
    "    time.sleep(0.01)\n",
    "    return len(splitted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to run and wait the sequantial code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cc42c2f0ddf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal_words_in_all_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtotal_words_in_all_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_words_in_all_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcount_word_in_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c1ccb2b31aee>\u001b[0m in \u001b[0;36mcount_word_in_statement\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0msplitted_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitted_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "total_words_in_all_data = 0\n",
    "for index in range(0, len(dataset)):\n",
    "    total_words_in_all_data = total_words_in_all_data + count_word_in_statement(dataset[index])\n",
    "    end = time.time() - start\n",
    "    if end >= 50:\n",
    "        print(\"More than {}s of computation time...\".format(end))\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('dask-scheduler:8786')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word in the dataset: 2038444\n",
      "Computation took 55.521080493927s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "futures = [client.submit(count_word_in_statement, data) for data in dataset]\n",
    "futures = client.submit(sum, futures)\n",
    "total_words_in_all_data = client.gather(futures)\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Total word in the dataset: {}\".format(total_words_in_all_data))\n",
    "print(\"Computation took {}s\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we increment the number of workers or threads per worker?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you feel like a hero and you don't be afraid to become old by standing in front of the PC, you can try to compare the sequential code and the distributed code by increasing the sleep time 100ms or 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How works the distribution and the scheduling of the processes?\n",
    "\n",
    "#### How a worker is choosen?\n",
    "Even though you can reduce and make some restrictions, e.g: restriction over worker resources, Dask automatically decides the suitable workers for your tasks by figuring out the optimized worker for each task.\n",
    "This means that, if a task has significant data dependencies or if the workers are under heavy load then this choice of worker can strongly impact global performance because the decision becomes heavy.\n",
    "\n",
    "Dask follows the following rules before to assign a task to a worker:\n",
    "+ If the task has no major dependencies and no restrictions then we find the least occupied worker.\n",
    "\n",
    "+ if a task has user-provided restrictions (for example it must run on a machine with a GPU) then we restrict the available pool of workers to just that set, otherwise, we consider all workers\n",
    "+ from the pool of workers Dask determinates the workers to whom the least amount of data would need to be transferred (means less overhead on the cluster and hence computation optimization).\n",
    "+  if some dependencies in the graph can be broken the will be assigned to the worker that currently has the fewest tasks.\n",
    "\n",
    "\n",
    "Dask also allows modifying the worker decision function in order to be more flexible and to improve the customization of a cluster. This means that particular processes or particular computational fields in which performances can be improved by customizing and optimizing the task's assignation decision can be made more performant.\n",
    "\n",
    "Breaking the dependencies in some cases is necessary, especially if each node has a lot of sons. In this case, each node with his sons must be removed from the graph and computed alone. This has a huge impact on performances and memory. On the other hand, this means that when a user submits a task, the computation graph must be scan to figuring out and optimizing this kind of dependencies.\n",
    "\n",
    "\n",
    "#### How choose the next task?\n",
    "Typically Dask follows those rules in order to choose the next task that must be executed:\n",
    "+ Run tasks on a first-come-first-served basis for fairness between multiple clients\n",
    "+ Run tasks that are part of the critical path in an effort to reduce total running time and minimize straggler workloads\n",
    "+ Run tasks that allow us to release many dependencies in an effort to keep the memory footprint small\n",
    "+ Run tasks that are related so that large chunks of work can be completely eliminated before running new chunks of work\n",
    "\n",
    "As you can see a part of the overhead on a cluster is principally caused by the optimization of the execution task decision. Even though these are rules implemented by Dask, in general, the majority of the Cluster, even if they are based on other frameworks and other architectures, follow the same similar approaches.\n",
    "\n",
    "On the other hand, some computational fields may require a different approach to decide which tasks can be executed, e.g: by using last-in-first-out approach or by giving a priority to each task in order to execute first some processes.\n",
    "\n",
    "In some cases, Dask optimization exploit also a partially last-in-first-out approach. When a worker finishes a task the immediate dependencies of that task get top priority. This encourages a behavior of finishing ongoing work immediately before starting new work. This often conflicts with the first-come-first-served objective but often results in shorter total runtimes and significantly reduced memory footprints.\n",
    "\n",
    "\n",
    "#### Where these decisions are made?\n",
    "\n",
    "The decision are basically made in small steps and in a different computation steps by client, scheduler, and workers:\n",
    "\n",
    "+ As we submit a graph from the *client* to the scheduler we automatically assign a numeric priority to each task of that graph. This priority focuses on computing deeply before broadly, preferring critical paths, and preferring nodes with many dependencies.\n",
    "\n",
    "+ When the graph reaches the scheduler the scheduler changes each of these numeric priorities into a tuple of two numbers, the first of which is an increasing counter, the second of which is the client-generated priority described above. This per-graph counter encourages a first-in-first-out policy between computations. All tasks from a previous call to compute have a higher priority than all tasks from a subsequent call to compute (or submit, persist, map, or any operation that generates futures).\n",
    "\n",
    "+ Whenever a task is ready to run the scheduler assigns it to a worker. The scheduler does not wait based on priority. However when the worker receives these tasks it considers their priorities when determining which tasks to prioritize for communication or for computation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker Resources\n",
    "\n",
    "Let's suppose that you want to run a proces over a cluster, but only in those machine that has a GPU or have at least 16Gb of RAM. Now let's imagin that you have a cluster of ten computers in which four have a GPU while the others no. In this case we want to balance tasks across the cluster with these resource constraints in mind, allocating GPU-constrained tasks to GPU-enabled workers. Additionally we need to be sure to constrain the number of GPU tasks that run concurrently on any given worker to ensure that we respect the provided limits.\n",
    "Clearly, this situation arises not only for GPUs but for many resources like tasks that require a large amount of memory at runtime, special disk access, or access to special hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you require workers with particular resources you must be sure that those resources are availables over the cluster.\n",
    "Otherwise your processes should be never executed.\n",
    "\n",
    "Let's try an example togheter: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, stop the workers that you have in your cluster and the scheduler. Start again the scheduler and then turn up two workers with those commands:\n",
    "\n",
    "+ ```dask-worker dask-scheduler:8786 --nprocs 1 --nthreads 1 --resources \"GPU=2\"```\n",
    "+ ```dask-worker dask-scheduler:8786 --nprocs 1 --nthreads 1 --resources \"GPU=1\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dask.distributed import Client\n",
    "client = Client('dask-scheduler:8786')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://dask-scheduler:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://dask-scheduler:8787/status' target='_blank'>http://dask-scheduler:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>1.86 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.0.2:8786' processes=2 threads=2, memory=1.86 GiB>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = []\n",
    "\n",
    "for i in range(100):\n",
    "    matrices.append(np.random.rand(4,3))\n",
    "\n",
    "def compute_polynomial_kernel(matrix):\n",
    "    polynomial_degree = 2\n",
    "    return np.power((np.dot(matrix, matrix.T)+1), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working on a matrix computation let's suppose that we want exploit the multi-gpu available only on some workers. \n",
    "Assume that we need to use 3 GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel is: [[11.31085973  8.3889741   5.03707346  5.09711245]\n",
      " [ 8.3889741   6.37683761  3.89621286  4.04516115]\n",
      " [ 5.03707346  3.89621286  3.49964908  2.57904128]\n",
      " [ 5.09711245  4.04516115  2.57904128  2.94232145]]\n",
      "\n",
      "Kernel is: [[4.13506279 3.32257555 3.21949346 4.63297478]\n",
      " [3.32257555 2.93649075 2.62897699 3.61644331]\n",
      " [3.21949346 2.62897699 2.60276804 3.54502137]\n",
      " [4.63297478 3.61644331 3.54502137 5.43885652]]\n",
      "\n",
      "Kernel is: [[5.46944747 2.57989935 5.66492042 3.10433365]\n",
      " [2.57989935 4.4778874  3.21030263 3.09063175]\n",
      " [5.66492042 3.21030263 6.03994106 3.37376929]\n",
      " [3.10433365 3.09063175 3.37376929 4.68339361]]\n",
      "\n",
      "Kernel is: [[3.7704245  3.46827838 3.85710052 5.74008353]\n",
      " [3.46827838 4.18294446 2.41707738 5.01557352]\n",
      " [3.85710052 2.41707738 7.04989638 6.48360299]\n",
      " [5.74008353 5.01557352 6.48360299 9.56915263]]\n",
      "\n",
      "Kernel is: [[3.64271467 4.30222419 3.97356234 3.10021083]\n",
      " [4.30222419 7.69508486 5.64963917 3.22015958]\n",
      " [3.97356234 5.64963917 4.80559519 3.48610139]\n",
      " [3.10021083 3.22015958 3.48610139 3.61585643]]\n",
      "\n",
      "Kernel is: [[6.21174467 3.24124747 4.10553214 6.19305341]\n",
      " [3.24124747 4.85775195 4.86127846 4.29404588]\n",
      " [4.10553214 4.86127846 5.2619889  4.59108838]\n",
      " [6.19305341 4.29404588 4.59108838 8.63086434]]\n",
      "\n",
      "Kernel is: [[1.44936807 1.91333706 1.57461475 1.73996873]\n",
      " [1.91333706 4.69213532 2.5722325  3.68572674]\n",
      " [1.57461475 2.5722325  3.71223783 2.46475953]\n",
      " [1.73996873 3.68572674 2.46475953 3.03021638]]\n",
      "\n",
      "Kernel is: [[3.75072583 2.20843055 3.36270531 2.69247178]\n",
      " [2.20843055 2.65193294 2.55680725 2.79295578]\n",
      " [3.36270531 2.55680725 3.6191913  3.48497151]\n",
      " [2.69247178 2.79295578 3.48497151 3.96500293]]\n",
      "\n",
      "Kernel is: [[4.37345455 1.95916654 4.42296337 3.22572244]\n",
      " [1.95916654 1.66591212 2.73035291 2.61630545]\n",
      " [4.42296337 2.73035291 6.72899302 5.78318029]\n",
      " [3.22572244 2.61630545 5.78318029 5.50695784]]\n",
      "\n",
      "Kernel is: [[1.52677888 1.87207477 1.49326995 1.58361053]\n",
      " [1.87207477 4.47846174 3.49273406 2.01642699]\n",
      " [1.49326995 3.49273406 4.5873026  1.77651615]\n",
      " [1.58361053 2.01642699 1.77651615 1.68114389]]\n",
      "\n",
      "Kernel is: [[4.37638494 3.62463182 4.02210473 2.79697903]\n",
      " [3.62463182 5.84233689 4.38063567 4.12182818]\n",
      " [4.02210473 4.38063567 4.55893198 4.18149262]\n",
      " [2.79697903 4.12182818 4.18149262 5.24121751]]\n",
      "\n",
      "Kernel is: [[4.37371828 3.24425576 4.18995915 3.63864974]\n",
      " [3.24425576 2.87475247 2.80311997 3.1527615 ]\n",
      " [4.18995915 2.80311997 4.39533448 3.25444273]\n",
      " [3.63864974 3.1527615  3.25444273 3.84203657]]\n",
      "\n",
      "Kernel is: [[7.12344257 6.08776209 2.38881885 5.40151897]\n",
      " [6.08776209 6.27716186 2.10666918 5.75167116]\n",
      " [2.38881885 2.10666918 1.47739075 1.84937762]\n",
      " [5.40151897 5.75167116 1.84937762 5.56204284]]\n",
      "\n",
      "Kernel is: [[4.4247182  4.2839482  4.0122432  2.56276502]\n",
      " [4.2839482  5.70346889 3.79360439 3.3121803 ]\n",
      " [4.0122432  3.79360439 4.06802386 2.25887116]\n",
      " [2.56276502 3.3121803  2.25887116 2.23366558]]\n",
      "\n",
      "Kernel is: [[7.13239668 4.17468867 2.47617548 6.26659601]\n",
      " [4.17468867 3.99879033 2.84185524 4.80975129]\n",
      " [2.47617548 2.84185524 2.26631877 3.08548281]\n",
      " [6.26659601 4.80975129 3.08548281 6.4635962 ]]\n",
      "\n",
      "Kernel is: [[3.56489614 1.87163673 2.71648614 1.76862996]\n",
      " [1.87163673 3.61929641 2.86682096 2.21357425]\n",
      " [2.71648614 2.86682096 3.7405882  1.60567434]\n",
      " [1.76862996 2.21357425 1.60567434 2.02087421]]\n",
      "\n",
      "Kernel is: [[1.75799527 3.26336835 1.9635204  2.07988516]\n",
      " [3.26336835 9.02614548 3.95054404 4.1609185 ]\n",
      " [1.9635204  3.95054404 2.81525206 2.47994054]\n",
      " [2.07988516 4.1609185  2.47994054 3.78276143]]\n",
      "\n",
      "Kernel is: [[3.38374796 2.30352951 2.41240798 3.21759193]\n",
      " [2.30352951 2.24462585 2.25626077 2.70004012]\n",
      " [2.41240798 2.25626077 2.53068216 3.41216763]\n",
      " [3.21759193 2.70004012 3.41216763 5.32003194]]\n",
      "\n",
      "Kernel is: [[2.90790566 2.74877221 3.41005692 2.44795985]\n",
      " [2.74877221 2.66547211 2.89182695 2.16099354]\n",
      " [3.41005692 2.89182695 6.36842539 4.51582165]\n",
      " [2.44795985 2.16099354 4.51582165 4.01197966]]\n",
      "\n",
      "Kernel is: [[6.03550108 5.87032588 4.15108883 2.49853279]\n",
      " [5.87032588 7.89444733 5.08865211 3.8103514 ]\n",
      " [4.15108883 5.08865211 3.78564149 2.79094423]\n",
      " [2.49853279 3.8103514  2.79094423 2.56744489]]\n",
      "\n",
      "Kernel is: [[3.30626462 3.16326857 3.44195848 3.30066789]\n",
      " [3.16326857 4.55172661 2.55444339 4.14602349]\n",
      " [3.44195848 2.55444339 4.29653064 3.13778025]\n",
      " [3.30066789 4.14602349 3.13778025 4.18245624]]\n",
      "\n",
      "Kernel is: [[3.8539472  3.18772643 2.83389309 1.67484563]\n",
      " [3.18772643 2.80490055 2.43480372 1.45535482]\n",
      " [2.83389309 2.43480372 2.31416429 1.53420958]\n",
      " [1.67484563 1.45535482 1.53420958 1.32854041]]\n",
      "\n",
      "Kernel is: [[2.12373624 2.07010008 1.68556437 2.67087319]\n",
      " [2.07010008 2.54407228 1.45732048 1.82363163]\n",
      " [1.68556437 1.45732048 1.54490217 2.41752054]\n",
      " [2.67087319 1.82363163 2.41752054 5.32882414]]\n",
      "\n",
      "Kernel is: [[3.37120217 2.7219211  2.41033132 4.48332078]\n",
      " [2.7219211  2.75338166 3.08219567 3.69315793]\n",
      " [2.41033132 3.08219567 4.26565358 3.44887322]\n",
      " [4.48332078 3.69315793 3.44887322 6.32601525]]\n",
      "\n",
      "Kernel is: [[ 6.87741281  4.58982284  8.03405098  7.14479005]\n",
      " [ 4.58982284  3.61978254  5.61663888  5.36427028]\n",
      " [ 8.03405098  5.61663888 10.10342818  9.13144943]\n",
      " [ 7.14479005  5.36427028  9.13144943  8.57904844]]\n",
      "\n",
      "Kernel is: [[3.11823976 2.40619349 2.55844797 3.00151537]\n",
      " [2.40619349 4.22266751 1.81859429 3.07015771]\n",
      " [2.55844797 1.81859429 2.99827487 2.80702837]\n",
      " [3.00151537 3.07015771 2.80702837 3.40399991]]\n",
      "\n",
      "Kernel is: [[7.21657474 2.41673933 4.25553372 5.12828239]\n",
      " [2.41673933 2.91140428 3.00741613 2.87046916]\n",
      " [4.25553372 3.00741613 4.61484719 3.12936948]\n",
      " [5.12828239 2.87046916 3.12936948 5.62611694]]\n",
      "\n",
      "Kernel is: [[4.10130969 2.25573289 3.77866158 1.49252962]\n",
      " [2.25573289 2.66210315 2.23978214 1.70616125]\n",
      " [3.77866158 2.23978214 3.87560321 1.58627997]\n",
      " [1.49252962 1.70616125 1.58627997 1.35470689]]\n",
      "\n",
      "Kernel is: [[7.06063983 2.92329815 3.77654206 5.70243012]\n",
      " [2.92329815 2.08429686 2.51076312 2.19047388]\n",
      " [3.77654206 2.51076312 3.19495461 2.48892433]\n",
      " [5.70243012 2.19047388 2.48892433 6.24123442]]\n",
      "\n",
      "Kernel is: [[2.26753502 3.18374068 2.96313606 2.11918578]\n",
      " [3.18374068 9.20881871 7.75032029 2.81645691]\n",
      " [2.96313606 7.75032029 7.24727528 2.60702656]\n",
      " [2.11918578 2.81645691 2.60702656 1.99605327]]\n",
      "\n",
      "Kernel is: [[1.48723194 1.9307253  2.19775035 1.60080899]\n",
      " [1.9307253  3.91548535 4.33168019 2.12323876]\n",
      " [2.19775035 4.33168019 5.21996628 2.5540626 ]\n",
      " [1.60080899 2.12323876 2.5540626  1.78195854]]\n",
      "\n",
      "Kernel is: [[3.56654752 2.03743198 3.33934712 3.12798808]\n",
      " [2.03743198 2.90687795 2.74823854 2.5995055 ]\n",
      " [3.33934712 2.74823854 4.17018472 3.73762142]\n",
      " [3.12798808 2.5995055  3.73762142 3.39990343]]\n",
      "\n",
      "Kernel is: [[5.63512313 1.66412249 3.17890564 2.35204248]\n",
      " [1.66412249 1.13149639 1.41932869 1.25055104]\n",
      " [3.17890564 1.41932869 2.95275391 1.85935246]\n",
      " [2.35204248 1.25055104 1.85935246 2.35935443]]\n",
      "\n",
      "Kernel is: [[3.00399303 1.73034864 2.98682565 1.87652545]\n",
      " [1.73034864 2.13580455 2.15407763 1.81053619]\n",
      " [2.98682565 2.15407763 3.49857265 2.10174664]\n",
      " [1.87652545 1.81053619 2.10174664 1.6738596 ]]\n",
      "\n",
      "Kernel is: [[7.40285767 4.15206057 4.47298917 5.37970963]\n",
      " [4.15206057 4.11668422 3.95707805 3.95069593]\n",
      " [4.47298917 3.95707805 4.82351119 3.64751916]\n",
      " [5.37970963 3.95069593 3.64751916 4.59689174]]\n",
      "\n",
      "Kernel is: [[8.81091197 4.5490967  4.18457025 8.16156676]\n",
      " [4.5490967  3.57109855 1.68269653 4.49185489]\n",
      " [4.18457025 1.68269653 3.82996124 3.85489165]\n",
      " [8.16156676 4.49185489 3.85489165 8.52202403]]\n",
      "\n",
      "Kernel is: [[5.22884147 5.30479691 5.77444564 3.86496569]\n",
      " [5.30479691 7.04496846 6.01795454 4.25089563]\n",
      " [5.77444564 6.01795454 6.8864759  4.89885682]\n",
      " [3.86496569 4.25089563 4.89885682 3.99707711]]\n",
      "\n",
      "Kernel is: [[4.0710959  4.23539013 2.41220862 2.93611616]\n",
      " [4.23539013 4.84087923 2.33135632 2.89717828]\n",
      " [2.41220862 2.33135632 1.91432995 2.43200911]\n",
      " [2.93611616 2.89717828 2.43200911 3.63031438]]\n",
      "\n",
      "Kernel is: [[10.21511702  4.67959571  2.90118252  4.20255853]\n",
      " [ 4.67959571  3.86171274  2.47206409  2.98575241]\n",
      " [ 2.90118252  2.47206409  3.1239272   2.11191665]\n",
      " [ 4.20255853  2.98575241  2.11191665  2.51980379]]\n",
      "\n",
      "Kernel is: [[4.62286535 4.55051655 3.98484394 4.12915552]\n",
      " [4.55051655 7.08266457 5.50367072 4.50815127]\n",
      " [3.98484394 5.50367072 5.82601271 2.75628801]\n",
      " [4.12915552 4.50815127 2.75628801 5.06086141]]\n",
      "\n",
      "Kernel is: [[7.60848077 4.31593657 4.7490255  3.7483165 ]\n",
      " [4.31593657 4.72127289 2.97334342 2.82643538]\n",
      " [4.7490255  2.97334342 4.28960073 1.72896401]\n",
      " [3.7483165  2.82643538 1.72896401 3.50037105]]\n",
      "\n",
      "Kernel is: [[5.76387985 4.65034858 4.187943   3.56227903]\n",
      " [4.65034858 4.07950005 4.07856837 3.21188658]\n",
      " [4.187943   4.07856837 8.51617335 3.19729603]\n",
      " [3.56227903 3.21188658 3.19729603 2.61503421]]\n",
      "\n",
      "Kernel is: [[2.21432992 1.96861999 2.20086815 1.8866754 ]\n",
      " [1.96861999 2.09702546 1.68633073 1.15781679]\n",
      " [2.20086815 1.68633073 2.75617675 2.14640645]\n",
      " [1.8866754  1.15781679 2.14640645 3.53868335]]\n",
      "\n",
      "Kernel is: [[1.73035121 2.76253245 1.89444145 2.66313807]\n",
      " [2.76253245 5.82421258 3.33026002 5.19192991]\n",
      " [1.89444145 3.33026002 3.13378304 2.91452212]\n",
      " [2.66313807 5.19192991 2.91452212 5.59241128]]\n",
      "\n",
      "Kernel is: [[2.9704404  3.13550979 3.76201455 3.87119476]\n",
      " [3.13550979 4.36370199 4.58762114 4.83527925]\n",
      " [3.76201455 4.58762114 5.40466405 5.4618142 ]\n",
      " [3.87119476 4.83527925 5.4618142  5.76770469]]\n",
      "\n",
      "Kernel is: [[3.19997122 3.55855003 3.0360998  2.36288175]\n",
      " [3.55855003 8.47968733 6.81565704 3.9779932 ]\n",
      " [3.0360998  6.81565704 5.85452197 2.77318339]\n",
      " [2.36288175 3.9779932  2.77318339 4.00915473]]\n",
      "\n",
      "Kernel is: [[3.53506974 2.8918566  2.02567817 2.18240384]\n",
      " [2.8918566  2.50184515 1.81731368 1.96486456]\n",
      " [2.02567817 1.81731368 2.09746904 2.67144533]\n",
      " [2.18240384 1.96486456 2.67144533 3.72224187]]\n",
      "\n",
      "Kernel is: [[2.78699775 1.60080562 3.06363009 1.854382  ]\n",
      " [1.60080562 2.08966966 1.86491126 2.34936453]\n",
      " [3.06363009 1.86491126 3.76983691 2.62558335]\n",
      " [1.854382   2.34936453 2.62558335 3.44492373]]\n",
      "\n",
      "Kernel is: [[3.7019931  3.68930936 2.74468162 3.26099737]\n",
      " [3.68930936 4.59039723 3.35103426 3.65524825]\n",
      " [2.74468162 3.35103426 3.37034947 3.27411759]\n",
      " [3.26099737 3.65524825 3.27411759 3.43992467]]\n",
      "\n",
      "Kernel is: [[5.08948392 6.32456282 3.73247902 3.78991341]\n",
      " [6.32456282 8.05394337 4.67141501 4.70206709]\n",
      " [3.73247902 4.67141501 3.54619797 3.05528799]\n",
      " [3.78991341 4.70206709 3.05528799 3.28196359]]\n",
      "\n",
      "Kernel is: [[4.44969957 2.03611093 4.53656338 4.79132348]\n",
      " [2.03611093 2.22964729 1.6867958  3.05020554]\n",
      " [4.53656338 1.6867958  4.87178131 4.38530158]\n",
      " [4.79132348 3.05020554 4.38530158 6.64391121]]\n",
      "\n",
      "Kernel is: [[1.79606564 1.46173572 2.45396186 1.64575405]\n",
      " [1.46173572 3.17440839 4.02994538 2.55889707]\n",
      " [2.45396186 4.02994538 7.03743746 3.10202935]\n",
      " [1.64575405 2.55889707 3.10202935 3.83368011]]\n",
      "\n",
      "Kernel is: [[1.9167231  2.98149756 2.78206875 1.5665701 ]\n",
      " [2.98149756 6.23660276 5.53906024 2.37883459]\n",
      " [2.78206875 5.53906024 5.34554045 2.33047914]\n",
      " [1.5665701  2.37883459 2.33047914 1.48818879]]\n",
      "\n",
      "Kernel is: [[1.32701954 1.57338948 2.17032065 1.32237826]\n",
      " [1.57338948 2.83936823 4.69114557 2.09531325]\n",
      " [2.17032065 4.69114557 9.28535639 3.37714488]\n",
      " [1.32237826 2.09531325 3.37714488 2.30294647]]\n",
      "\n",
      "Kernel is: [[6.02125532 2.6149097  3.28901976 4.02608422]\n",
      " [2.6149097  1.96998852 2.2690434  2.36012821]\n",
      " [3.28901976 2.2690434  3.15461455 3.06268088]\n",
      " [4.02608422 2.36012821 3.06268088 3.27408037]]\n",
      "\n",
      "Kernel is: [[3.92550949 3.39819371 1.23917705 3.30599601]\n",
      " [3.39819371 2.97560202 1.20774226 2.92511555]\n",
      " [1.23917705 1.20774226 1.11533925 1.54376955]\n",
      " [3.30599601 2.92511555 1.54376955 5.64122648]]\n",
      "\n",
      "Kernel is: [[6.1377948  4.08257074 5.38672142 1.9219415 ]\n",
      " [4.08257074 2.93751035 3.72084032 1.68795409]\n",
      " [5.38672142 3.72084032 5.17400208 1.87889775]\n",
      " [1.9219415  1.68795409 1.87889775 1.52735186]]\n",
      "\n",
      "Kernel is: [[5.42580184 2.1773402  2.81817917 2.53857845]\n",
      " [2.1773402  1.82039159 1.32608771 1.90014347]\n",
      " [2.81817917 1.32608771 2.97870741 2.97747737]\n",
      " [2.53857845 1.90014347 2.97747737 4.80636425]]\n",
      "\n",
      "Kernel is: [[3.13538024 4.72672765 3.90598074 3.08184887]\n",
      " [4.72672765 8.91907203 6.80659706 3.99663767]\n",
      " [3.90598074 6.80659706 7.53635412 2.9949759 ]\n",
      " [3.08184887 3.99663767 2.9949759  3.60274091]]\n",
      "\n",
      "Kernel is: [[5.33728485 4.15533907 2.02325928 6.26270329]\n",
      " [4.15533907 5.08665949 2.44997586 4.41006585]\n",
      " [2.02325928 2.44997586 1.67518721 2.11005678]\n",
      " [6.26270329 4.41006585 2.11005678 7.56233759]]\n",
      "\n",
      "Kernel is: [[2.6903282  3.06610855 1.88370503 1.8748854 ]\n",
      " [3.06610855 9.07871429 3.50132306 4.93636898]\n",
      " [1.88370503 3.50132306 2.6129737  2.12038012]\n",
      " [1.8748854  4.93636898 2.12038012 3.16268805]]\n",
      "\n",
      "Kernel is: [[5.03719162 4.01226974 3.13231043 1.99050281]\n",
      " [4.01226974 3.61414986 2.86731209 1.67428495]\n",
      " [3.13231043 2.86731209 2.52636016 1.41858385]\n",
      " [1.99050281 1.67428495 1.41858385 1.37148902]]\n",
      "\n",
      "Kernel is: [[3.53295691 4.5013339  4.70035462 4.3658064 ]\n",
      " [4.5013339  7.23261658 5.72024188 7.37053388]\n",
      " [4.70035462 5.72024188 6.72166774 5.33089805]\n",
      " [4.3658064  7.37053388 5.33089805 7.87271346]]\n",
      "\n",
      "Kernel is: [[3.48506761 2.53991497 3.42772841 2.4221585 ]\n",
      " [2.53991497 3.05843157 2.27847392 3.44697477]\n",
      " [3.42772841 2.27847392 3.48809066 2.31100906]\n",
      " [2.4221585  3.44697477 2.31100906 5.72217762]]\n",
      "\n",
      "Kernel is: [[2.16235088 2.96086834 2.13038961 1.54836042]\n",
      " [2.96086834 7.46278911 3.88152166 4.817744  ]\n",
      " [2.13038961 3.88152166 3.64580722 2.1520607 ]\n",
      " [1.54836042 4.817744   2.1520607  5.02122251]]\n",
      "\n",
      "Kernel is: [[3.63666534 1.18322157 4.50175267 3.30548768]\n",
      " [1.18322157 1.20580462 1.6147292  1.22123267]\n",
      " [4.50175267 1.6147292  7.62306654 3.91087669]\n",
      " [3.30548768 1.22123267 3.91087669 3.34002586]]\n",
      "\n",
      "Kernel is: [[4.47096193 3.59466227 3.21088319 3.78231738]\n",
      " [3.59466227 3.85950398 2.12295084 3.07151816]\n",
      " [3.21088319 2.12295084 3.89449259 3.691715  ]\n",
      " [3.78231738 3.07151816 3.691715   4.06573163]]\n",
      "\n",
      "Kernel is: [[4.39490902 1.60513747 4.11630195 2.18539877]\n",
      " [1.60513747 1.2168163  1.66019452 1.33065105]\n",
      " [4.11630195 1.66019452 4.79068633 3.32896288]\n",
      " [2.18539877 1.33065105 3.32896288 3.47304216]]\n",
      "\n",
      "Kernel is: [[6.0755793  3.92365232 2.67433317 5.11035246]\n",
      " [3.92365232 3.95916452 2.23891344 3.04099865]\n",
      " [2.67433317 2.23891344 1.67489881 2.20443839]\n",
      " [5.11035246 3.04099865 2.20443839 6.67752997]]\n",
      "\n",
      "Kernel is: [[3.13358283 3.91161438 2.36100075 2.44064313]\n",
      " [3.91161438 5.31781586 2.86295794 3.09058399]\n",
      " [2.36100075 2.86295794 1.90915909 1.95453676]\n",
      " [2.44064313 3.09058399 1.95453676 2.07601434]]\n",
      "\n",
      "Kernel is: [[7.36420999 3.31443359 5.6512047  4.87745278]\n",
      " [3.31443359 2.53933003 2.4325355  2.62978194]\n",
      " [5.6512047  2.4325355  4.94775765 3.34212506]\n",
      " [4.87745278 2.62978194 3.34212506 4.32402146]]\n",
      "\n",
      "Kernel is: [[4.65411625 4.7099661  5.51760272 1.82026284]\n",
      " [4.7099661  5.91787363 6.66387497 2.57837561]\n",
      " [5.51760272 6.66387497 7.70527964 2.76420056]\n",
      " [1.82026284 2.57837561 2.76420056 2.10467149]]\n",
      "\n",
      "Kernel is: [[4.67643674 3.79530503 3.1728861  1.4603085 ]\n",
      " [3.79530503 3.30701063 2.61584502 1.4345637 ]\n",
      " [3.1728861  2.61584502 3.11636462 1.80703733]\n",
      " [1.4603085  1.4345637  1.80703733 1.57892133]]\n",
      "\n",
      "Kernel is: [[2.13078151 1.71074199 1.48793731 2.44798652]\n",
      " [1.71074199 1.50361772 1.52215872 1.99088316]\n",
      " [1.48793731 1.52215872 3.57331528 1.53635937]\n",
      " [2.44798652 1.99088316 1.53635937 3.31283246]]\n",
      "\n",
      "Kernel is: [[3.82062139 3.65365005 4.61895607 3.0369197 ]\n",
      " [3.65365005 5.36259463 4.23575327 2.88939664]\n",
      " [4.61895607 4.23575327 5.99937451 3.8718551 ]\n",
      " [3.0369197  2.88939664 3.8718551  2.76500014]]\n",
      "\n",
      "Kernel is: [[2.47162678 2.81812676 1.93405904 3.16927124]\n",
      " [2.81812676 3.60447224 2.1118703  3.31320135]\n",
      " [1.93405904 2.1118703  3.08382726 3.32588336]\n",
      " [3.16927124 3.31320135 3.32588336 5.48861804]]\n",
      "\n",
      "Kernel is: [[3.91004697 2.7232741  2.41976068 1.81955239]\n",
      " [2.7232741  2.87926708 1.60895762 1.08836493]\n",
      " [2.41976068 1.60895762 1.96492832 2.0633924 ]\n",
      " [1.81955239 1.08836493 2.0633924  3.3912128 ]]\n",
      "\n",
      "Kernel is: [[3.99014381 3.31823979 2.09663187 3.37807207]\n",
      " [3.31823979 4.75290157 2.36430725 2.59047078]\n",
      " [2.09663187 2.36430725 1.85898083 2.35087684]\n",
      " [3.37807207 2.59047078 2.35087684 4.14883851]]\n",
      "\n",
      "Kernel is: [[5.33892543 5.04734816 5.01344336 3.95671448]\n",
      " [5.04734816 5.7856681  5.96554595 5.69836035]\n",
      " [5.01344336 5.96554595 6.20861299 6.13112629]\n",
      " [3.95671448 5.69836035 6.13112629 7.07767482]]\n",
      "\n",
      "Kernel is: [[4.75574708 4.64729646 1.53768389 1.36050329]\n",
      " [4.64729646 5.27681908 1.21539686 1.147455  ]\n",
      " [1.53768389 1.21539686 3.40693783 2.18996599]\n",
      " [1.36050329 1.147455   2.18996599 1.62613829]]\n",
      "\n",
      "Kernel is: [[1.81599213 1.63543637 2.08768802 2.2055457 ]\n",
      " [1.63543637 1.50419282 1.77389553 1.93800776]\n",
      " [2.08768802 1.77389553 3.78190562 3.5338822 ]\n",
      " [2.2055457  1.93800776 3.5338822  4.96925433]]\n",
      "\n",
      "Kernel is: [[1.99304143 1.47621926 2.03829774 1.78946708]\n",
      " [1.47621926 1.82230334 1.60160663 1.84305471]\n",
      " [2.03829774 1.60160663 2.2659978  1.94793513]\n",
      " [1.78946708 1.84305471 1.94793513 2.01136522]]\n",
      "\n",
      "Kernel is: [[6.15573474 3.3017238  2.7174738  7.20977383]\n",
      " [3.3017238  2.34274515 2.01704212 3.63989657]\n",
      " [2.7174738  2.01704212 2.78421664 3.64117297]\n",
      " [7.20977383 3.63989657 3.64117297 9.16739699]]\n",
      "\n",
      "Kernel is: [[4.04880777 2.17811067 2.8273713  2.6415722 ]\n",
      " [2.17811067 1.93603396 1.7543809  1.75999006]\n",
      " [2.8273713  1.7543809  2.30115367 1.54390496]\n",
      " [2.6415722  1.75999006 1.54390496 3.78910944]]\n",
      "\n",
      "Kernel is: [[4.28311311 2.88072244 5.12858237 2.7036644 ]\n",
      " [2.88072244 2.40353734 3.12977637 1.57004801]\n",
      " [5.12858237 3.12977637 6.39921351 3.32104555]\n",
      " [2.7036644  1.57004801 3.32104555 4.8803246 ]]\n",
      "\n",
      "Kernel is: [[1.84432907 2.71619486 1.71993392 2.112171  ]\n",
      " [2.71619486 5.09368197 3.2128013  3.22442204]\n",
      " [1.71993392 3.2128013  4.25208077 2.1667371 ]\n",
      " [2.112171   3.22442204 2.1667371  2.9153342 ]]\n",
      "\n",
      "Kernel is: [[2.31109858 2.0010806  1.91838022 3.10592923]\n",
      " [2.0010806  1.77375329 1.69929609 2.63261868]\n",
      " [1.91838022 1.69929609 2.66299262 2.64969219]\n",
      " [3.10592923 2.63261868 2.64969219 5.31044501]]\n",
      "\n",
      "Kernel is: [[1.43469712 1.63494213 1.69032376 1.55032958]\n",
      " [1.63494213 2.20276214 2.01892777 1.83286153]\n",
      " [1.69032376 2.01892777 2.76255575 3.13364902]\n",
      " [1.55032958 1.83286153 3.13364902 4.29663169]]\n",
      "\n",
      "Kernel is: [[1.64796876 1.669144   2.26726287 1.98664205]\n",
      " [1.669144   4.8444352  4.16065872 1.97156089]\n",
      " [2.26726287 4.16065872 5.78392751 2.29055204]\n",
      " [1.98664205 1.97156089 2.29055204 3.24120937]]\n",
      "\n",
      "Kernel is: [[6.48962224 3.51037803 1.72247047 4.26807679]\n",
      " [3.51037803 3.68664793 1.91191065 3.04059336]\n",
      " [1.72247047 1.91191065 1.38193024 1.79784334]\n",
      " [4.26807679 3.04059336 1.79784334 4.14745038]]\n",
      "\n",
      "Kernel is: [[7.1518892  3.60253746 3.74957857 4.76606015]\n",
      " [3.60253746 2.78288466 2.34691447 3.28663757]\n",
      " [3.74957857 2.34691447 2.3593261  2.7208369 ]\n",
      " [4.76606015 3.28663757 2.7208369  4.94576196]]\n",
      "\n",
      "Kernel is: [[1.94301317 2.95194941 2.9035534  2.49377222]\n",
      " [2.95194941 5.41925556 5.2776248  4.25398396]\n",
      " [2.9035534  5.2776248  5.29790002 4.07078338]\n",
      " [2.49377222 4.25398396 4.07078338 3.49305319]]\n",
      "\n",
      "Kernel is: [[5.3788825  3.09455831 4.00168281 5.66338917]\n",
      " [3.09455831 3.95337079 3.31691479 3.73557832]\n",
      " [4.00168281 3.31691479 4.04477074 4.13571594]\n",
      " [5.66338917 3.73557832 4.13571594 6.33426812]]\n",
      "\n",
      "Kernel is: [[2.47093777 2.41669472 2.2888399  1.72961557]\n",
      " [2.41669472 2.45737469 2.3768837  1.87810279]\n",
      " [2.2888399  2.3768837  2.33136488 1.92592853]\n",
      " [1.72961557 1.87810279 1.92592853 1.947491  ]]\n",
      "\n",
      "Kernel is: [[2.31939035 2.09990498 1.37626683 2.31033984]\n",
      " [2.09990498 3.0099808  2.04272621 3.52234805]\n",
      " [1.37626683 2.04272621 1.71796181 2.48405614]\n",
      " [2.31033984 3.52234805 2.48405614 4.70201806]]\n",
      "\n",
      "Kernel is: [[3.44871038 2.67914083 2.38158259 3.49421296]\n",
      " [2.67914083 5.3784057  3.52862274 4.25595906]\n",
      " [2.38158259 3.52862274 3.07565043 4.36771848]\n",
      " [3.49421296 4.25595906 4.36771848 7.49349495]]\n",
      "\n",
      "Kernel is: [[2.63498817 4.07299679 3.30840105 2.58925869]\n",
      " [4.07299679 7.71373885 4.81952875 4.70918402]\n",
      " [3.30840105 4.81952875 5.56546192 2.40167045]\n",
      " [2.58925869 4.70918402 2.40167045 3.51018175]]\n",
      "\n",
      "Kernel is: [[2.75617678 2.82180245 3.43889927 2.33721576]\n",
      " [2.82180245 3.10394708 3.52362896 2.42418383]\n",
      " [3.43889927 3.52362896 4.47576421 2.86879736]\n",
      " [2.33721576 2.42418383 2.86879736 2.06283321]]\n",
      "\n",
      "Kernel is: [[6.49028981 4.92456062 6.09012574 6.10242151]\n",
      " [4.92456062 6.97939358 6.13729107 4.77236969]\n",
      " [6.09012574 6.13729107 6.65415536 5.737014  ]\n",
      " [6.10242151 4.77236969 5.737014   5.76806647]]\n",
      "\n",
      "Kernel is: [[ 4.34310067  4.52004614  2.38713344  5.67349557]\n",
      " [ 4.52004614  5.43881423  3.05803339  6.651368  ]\n",
      " [ 2.38713344  3.05803339  3.09543476  4.91755143]\n",
      " [ 5.67349557  6.651368    4.91755143 11.25431749]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed = [client.submit(compute_polynomial_kernel, matrix, resources={'GPU': 3}) for matrix in matrices]\n",
    "\n",
    "kernels = client.gather(processed)\n",
    "\n",
    "for i in kernels:\n",
    "    print(\"Kernel is: {}\".format(i))\n",
    "    print()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nothing is happening but the code still running...... Let's try to add on-the-fly a worker with 3 GPUs\n",
    "\n",
    "```dask-worker 192.168.1.12:8786 --nprocs 1 --nthreads 1 --resources \"GPU=3\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker-compose run  -e DASK_WORKER_RESOURCES=3 -e DASK_WORKER_RESOURCES_NAME=GPU dask-worker-custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Compute the traces of all the generated matrix. Execute this code over 2 workers with 2 \"SpecialCPU\" each one.\n",
    "You must use the ```map``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('dask-scheduler:8786')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://dask-scheduler:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://dask-scheduler:8787/status' target='_blank'>http://dask-scheduler:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>3</li>\n",
       "  <li><b>Memory: </b>2.79 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.0.2:8786' processes=3 threads=3, memory=2.79 GiB>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = [np.random.randint(low=m, high=m+1, size=(4, 3)) for m in (range(11))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel is: 0\n",
      "\n",
      "Kernel is: 3\n",
      "\n",
      "Kernel is: 6\n",
      "\n",
      "Kernel is: 9\n",
      "\n",
      "Kernel is: 12\n",
      "\n",
      "Kernel is: 15\n",
      "\n",
      "Kernel is: 18\n",
      "\n",
      "Kernel is: 21\n",
      "\n",
      "Kernel is: 24\n",
      "\n",
      "Kernel is: 27\n",
      "\n",
      "Kernel is: 30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed = client.map(np.trace, matrices, resources={'GPU': 2})\n",
    "\n",
    "kernels = client.gather(processed)\n",
    "\n",
    "for i in kernels:\n",
    "    print(\"Kernel is: {}\".format(i))\n",
    "    print()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "Execute the code of the \"howmany_within_range\" exercise from the previous lecture, into a worker with 256Gb of RAM. Map function is not allowed.\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "client = Client('dask-scheduler:8786')\n",
    "\n",
    "## creation of a matrix of 100 rows and 10 columns with each value between 0 and 100.\n",
    "np.random.RandomState(42)\n",
    "arr = np.random.randint(0, 100, size=[100, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://dask-scheduler:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://dask-scheduler:8787/status' target='_blank'>http://dask-scheduler:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>3</li>\n",
       "  <li><b>Memory: </b>2.79 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.18.0.2:8786' processes=3 threads=3, memory=2.79 GiB>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e22a740084cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhowmany_within_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'MEMORY'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2.56e9\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"howmany_within_range is: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1973\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m                 \u001b[0mlocal_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1975\u001b[0;31m             return self.sync(\n\u001b[0m\u001b[1;32m   1976\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m                 \u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             return sync(\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def howmany_within_range(row):\n",
    "    \"\"\"Returns how many numbers lie within 0 and 10 in the given `row`\"\"\"\n",
    "    count = 0\n",
    "    for n in row:\n",
    "        if 0 <= n <= 10:\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "\n",
    "futures = [client.submit(howmany_within_range, row, resources={'MEMORY':256e9}) for row in arr]\n",
    "results = client.gather(futures)\n",
    "for i in results:\n",
    "    print(\"howmany_within_range is: {}\".format(i))\n",
    "    print()\n",
    "    \n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
